{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>1.400</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.657</td>\n",
       "      <td>2.33</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>1.167</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.881</td>\n",
       "      <td>3.60</td>\n",
       "      <td>18</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>108</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.741</td>\n",
       "      <td>4.43</td>\n",
       "      <td>31</td>\n",
       "      <td>80</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>1.400</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.743</td>\n",
       "      <td>4.33</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.944</td>\n",
       "      <td>2.25</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   F1  F2   F3     F4     F5     F6    F7  F8  F9  F10  label\n",
       "0   5   7   35  1.400  0.400  0.657  2.33  14  23    6      1\n",
       "1   6   7   42  1.167  0.429  0.881  3.60  18  37    5      1\n",
       "2   6  18  108  3.000  0.287  0.741  4.43  31  80    7      1\n",
       "3   5   7   35  1.400  0.371  0.743  4.33  13  26    3      1\n",
       "4   6   3   18  0.500  0.500  0.944  2.25   9  17    4      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./datasets/page-blocks.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
      "        27,  28,  29,  30,  31,  32,  33,  34,  36,  37,  38,  39,  41,\n",
      "        42,  43,  44,  45,  47,  48,  49,  52,  53,  54,  55,  58,  59,\n",
      "        60,  63,  64,  65,  66,  67,  68,  69,  71,  72,  74,  76,  77,\n",
      "        79,  81,  82,  83,  84,  85,  86,  87,  91,  93,  94,  95,  98,\n",
      "       100, 101, 105, 117, 118, 128, 132, 136, 153, 158, 160, 163, 166,\n",
      "       168, 174, 178, 186, 187, 197, 212, 261, 304, 306, 311, 430, 804],\n",
      "      dtype=int64), array([254,  87,  58,  64, 271, 351, 831, 940, 903, 630, 326, 164, 103,\n",
      "        89,  20,  46,  35,  10,  11,   8,   5,  15,  16,  39,  33,   6,\n",
      "         7,  15,   5,   2,   7,   3,   3,   4,   6,   5,  10,   3,   1,\n",
      "         2,   1,   1,   1,   2,   1,   1,   2,   3,   5,   1,   1,   1,\n",
      "         1,   2,   1,   1,   1,   2,   1,   1,   1,   1,   1,   1,   3,\n",
      "         1,   1,   1,   6,   1,   1,   1,   1,   1,   2,   1,   1,   1,\n",
      "         1,   1,   1,   1,   1,   1,   1,   1,   2,   1,   1,   1,   1,\n",
      "         2,   1,   1,   1,   2,   1,   1,   1,   1,   1,   1,   1,   1],\n",
      "      dtype=int64))\n",
      "(array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
      "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
      "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
      "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
      "        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
      "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
      "       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
      "       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
      "       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
      "       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,\n",
      "       157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "       170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
      "       183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "       196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
      "       209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221,\n",
      "       222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235,\n",
      "       236, 238, 239, 240, 241, 242, 243, 244, 245, 246, 248, 249, 250,\n",
      "       251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
      "       264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276,\n",
      "       277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 291, 292,\n",
      "       293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305,\n",
      "       306, 307, 309, 310, 311, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "       322, 323, 325, 326, 327, 330, 331, 332, 333, 334, 335, 336, 337,\n",
      "       339, 340, 341, 342, 343, 344, 346, 347, 348, 349, 350, 352, 353,\n",
      "       354, 356, 357, 358, 359, 363, 364, 367, 369, 370, 371, 372, 375,\n",
      "       376, 377, 378, 379, 382, 383, 385, 386, 389, 390, 391, 393, 395,\n",
      "       397, 398, 399, 400, 402, 403, 404, 405, 407, 408, 409, 410, 412,\n",
      "       413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 427,\n",
      "       430, 433, 435, 436, 439, 440, 441, 442, 446, 453, 455, 457, 461,\n",
      "       462, 463, 464, 465, 468, 469, 470, 471, 472, 474, 475, 487, 488,\n",
      "       490, 491, 492, 494, 495, 497, 498, 499, 500, 504, 505, 506, 508,\n",
      "       509, 510, 511, 518, 519, 520, 521, 523, 524, 525, 532, 533, 534,\n",
      "       535, 536, 537, 538, 541, 544, 547, 550, 552, 553], dtype=int64), array([ 65,  28,  33,  73,  45,  59, 112, 105, 103,  64, 105, 126, 118,\n",
      "       113,  63,  83,  89,  96, 102,  90,  67,  68,  66,  47,  54,  53,\n",
      "        46,  39,  50,  45,  51,  62,  57,  49,  49,  50,  40,  47,  45,\n",
      "        50,  54,  37,  47,  36,  37,  40,  40,  33,  33,  26,  18,  25,\n",
      "        26,  26,  11,  14,  20,  15,  21,  15,  20,  21,  25,  25,  18,\n",
      "         9,  20,   6,  27,  20,  31,  19,  11,   9,  22,  16,  10,   7,\n",
      "        18,  24,  17,  38,  28,  24,  15,  18,   9,   6,  11,  11,  13,\n",
      "        14,  14,  15,  16,  38,  16,  28,  24,  22,  21,  16,  13,  15,\n",
      "         9,  13,  18,  16,  11,   6,   5,   6,   3,   7,  10,  16,  11,\n",
      "        17,  10,   6,  14,   9,  18,   8,   9,  12,   7,   6,   5,   9,\n",
      "         7,   8,   5,   2,  10,   4,   7,   5,   1,   4,   8,   2,   4,\n",
      "         3,   6,   3,   6,   9,   1,   8,   9,   8,   4,   7,  14,   2,\n",
      "         6,   6,   7,   3,   6,   7,   5,   2,   3,   5,   5,   7,   7,\n",
      "         7,   6,   7,   2,   4,   7,   5,   6,   5,   3,   8,   9,   2,\n",
      "        12,  12,  12,  13,   8,   1,   4,   4,   3,   4,   4,   3,   3,\n",
      "         2,   4,   9,   4,   1,   4,   2,   5,   1,   4,   2,   4,   2,\n",
      "         2,   1,   2,   2,   6,   5,   7,   4,   4,   4,   4,   1,   2,\n",
      "         3,   2,   2,   1,   6,   5,   1,   2,   5,   2,   4,   2,   1,\n",
      "         3,   2,   2,   7,   1,   5,   4,   1,   8,   1,   2,   6,   5,\n",
      "         6,   3,   2,   1,   1,   5,   3,   2,   5,   1,  15,  15,   4,\n",
      "         2,   1,   3,   4,   7,   2,   1,  31,  25,   2,   3,   3,   1,\n",
      "         4,   4,   4,   7,   3,   2,   2,   7,   4,   3,   3,   3,   5,\n",
      "         1,   3,   1,   1,   1,   3,   3,   3,   3,   3,   3,   2,   2,\n",
      "         2,   1,   4,   1,   3,   5,   2,   1,   1,   1,   3,   3,   2,\n",
      "         2,   2,   2,   4,   1,   3,   4,   2,   3,   1,   1,   2,   6,\n",
      "         1,   6,   3,   6,   3,   4,   6,   2,   3,   2,   3,   2,   3,\n",
      "         1,   3,   3,   1,   2,   1,   1,   3,   2,   1,   2,   1,   2,\n",
      "         2,   1,   2,   1,   2,   1,   1,   1,   3,   2,   1,   1,   1,\n",
      "         1,   3,   2,   1,   2,   1,   1,   1,   2,   2,   5,   7,   2,\n",
      "         3,   2,   2,   1,   2,   1,   2,   1,   1,   1,   1,   3,   2,\n",
      "         1,   3,   1,   1,   1,   2,   1,   1,   1,   1,   1,   1,   1,\n",
      "         1,   3,   2,   2,   1,   1,   1,   3,   1,   1,   1,   1,   1,\n",
      "         1,   1,   2,   1,   1,   3,   2,   1,   2,   1,   1,   1,   9,\n",
      "         3,  11,  10,   1,   1,   1,   1,   1,   1,   1,   2,   2,   8,\n",
      "        22,  12,  13,   4,   1,   1,   1,   2,   1,   1], dtype=int64))\n",
      "(array([     7,      8,      9, ..., 140752, 142290, 143993], dtype=int64), array([11, 18, 24, ...,  1,  1,  1], dtype=int64))\n",
      "(array([7.00e-03, 9.00e-03, 1.20e-02, ..., 3.79e+02, 4.13e+02, 5.37e+02]), array([1, 1, 2, ..., 1, 1, 1], dtype=int64))\n",
      "(array([0.052, 0.055, 0.056, 0.057, 0.059, 0.06 , 0.063, 0.065, 0.067,\n",
      "       0.07 , 0.072, 0.073, 0.074, 0.075, 0.077, 0.078, 0.079, 0.08 ,\n",
      "       0.081, 0.084, 0.087, 0.088, 0.089, 0.09 , 0.091, 0.092, 0.093,\n",
      "       0.094, 0.095, 0.096, 0.097, 0.098, 0.099, 0.1  , 0.101, 0.102,\n",
      "       0.103, 0.104, 0.105, 0.106, 0.107, 0.108, 0.109, 0.11 , 0.111,\n",
      "       0.113, 0.114, 0.115, 0.116, 0.117, 0.118, 0.119, 0.12 , 0.121,\n",
      "       0.123, 0.124, 0.125, 0.126, 0.127, 0.128, 0.129, 0.13 , 0.131,\n",
      "       0.132, 0.133, 0.134, 0.135, 0.136, 0.137, 0.138, 0.139, 0.14 ,\n",
      "       0.141, 0.142, 0.143, 0.144, 0.145, 0.146, 0.147, 0.148, 0.149,\n",
      "       0.15 , 0.151, 0.152, 0.153, 0.154, 0.155, 0.156, 0.157, 0.158,\n",
      "       0.159, 0.16 , 0.161, 0.162, 0.163, 0.164, 0.165, 0.166, 0.167,\n",
      "       0.168, 0.169, 0.17 , 0.171, 0.172, 0.173, 0.174, 0.175, 0.176,\n",
      "       0.177, 0.178, 0.179, 0.18 , 0.181, 0.182, 0.183, 0.184, 0.185,\n",
      "       0.186, 0.187, 0.188, 0.189, 0.19 , 0.191, 0.192, 0.193, 0.194,\n",
      "       0.195, 0.196, 0.197, 0.198, 0.199, 0.2  , 0.201, 0.202, 0.203,\n",
      "       0.204, 0.205, 0.206, 0.207, 0.208, 0.209, 0.21 , 0.211, 0.212,\n",
      "       0.213, 0.214, 0.215, 0.216, 0.217, 0.218, 0.219, 0.22 , 0.221,\n",
      "       0.222, 0.223, 0.224, 0.225, 0.226, 0.227, 0.228, 0.229, 0.23 ,\n",
      "       0.231, 0.232, 0.233, 0.234, 0.235, 0.236, 0.237, 0.238, 0.239,\n",
      "       0.24 , 0.241, 0.242, 0.243, 0.244, 0.245, 0.246, 0.247, 0.248,\n",
      "       0.249, 0.25 , 0.251, 0.252, 0.253, 0.254, 0.255, 0.256, 0.257,\n",
      "       0.258, 0.259, 0.26 , 0.261, 0.262, 0.263, 0.264, 0.265, 0.266,\n",
      "       0.267, 0.268, 0.269, 0.27 , 0.271, 0.272, 0.273, 0.274, 0.275,\n",
      "       0.276, 0.277, 0.278, 0.279, 0.28 , 0.281, 0.282, 0.283, 0.284,\n",
      "       0.285, 0.286, 0.287, 0.288, 0.289, 0.29 , 0.291, 0.292, 0.293,\n",
      "       0.294, 0.295, 0.296, 0.297, 0.298, 0.299, 0.3  , 0.301, 0.302,\n",
      "       0.303, 0.304, 0.305, 0.306, 0.307, 0.308, 0.309, 0.31 , 0.311,\n",
      "       0.312, 0.313, 0.314, 0.315, 0.316, 0.317, 0.318, 0.319, 0.32 ,\n",
      "       0.321, 0.322, 0.323, 0.324, 0.325, 0.326, 0.327, 0.328, 0.329,\n",
      "       0.33 , 0.331, 0.332, 0.333, 0.334, 0.335, 0.336, 0.337, 0.338,\n",
      "       0.339, 0.34 , 0.341, 0.342, 0.343, 0.344, 0.345, 0.346, 0.347,\n",
      "       0.348, 0.349, 0.35 , 0.351, 0.352, 0.353, 0.354, 0.355, 0.356,\n",
      "       0.357, 0.358, 0.359, 0.36 , 0.361, 0.362, 0.363, 0.364, 0.365,\n",
      "       0.366, 0.367, 0.368, 0.369, 0.37 , 0.371, 0.372, 0.373, 0.374,\n",
      "       0.375, 0.376, 0.377, 0.378, 0.379, 0.38 , 0.381, 0.382, 0.383,\n",
      "       0.384, 0.385, 0.386, 0.387, 0.388, 0.389, 0.39 , 0.391, 0.392,\n",
      "       0.393, 0.394, 0.395, 0.396, 0.397, 0.398, 0.399, 0.4  , 0.401,\n",
      "       0.402, 0.403, 0.404, 0.405, 0.406, 0.407, 0.408, 0.409, 0.41 ,\n",
      "       0.411, 0.412, 0.413, 0.414, 0.415, 0.416, 0.417, 0.418, 0.419,\n",
      "       0.42 , 0.421, 0.422, 0.423, 0.424, 0.425, 0.426, 0.427, 0.428,\n",
      "       0.429, 0.43 , 0.431, 0.432, 0.433, 0.434, 0.435, 0.436, 0.437,\n",
      "       0.438, 0.439, 0.44 , 0.441, 0.442, 0.443, 0.444, 0.445, 0.446,\n",
      "       0.447, 0.448, 0.449, 0.45 , 0.451, 0.452, 0.453, 0.454, 0.455,\n",
      "       0.456, 0.457, 0.458, 0.459, 0.46 , 0.461, 0.462, 0.463, 0.464,\n",
      "       0.465, 0.466, 0.467, 0.468, 0.469, 0.47 , 0.471, 0.472, 0.473,\n",
      "       0.474, 0.475, 0.476, 0.477, 0.478, 0.479, 0.48 , 0.481, 0.482,\n",
      "       0.483, 0.484, 0.485, 0.486, 0.487, 0.488, 0.489, 0.49 , 0.491,\n",
      "       0.492, 0.493, 0.494, 0.495, 0.496, 0.497, 0.498, 0.499, 0.5  ,\n",
      "       0.501, 0.503, 0.504, 0.505, 0.506, 0.507, 0.508, 0.509, 0.51 ,\n",
      "       0.511, 0.512, 0.513, 0.514, 0.515, 0.516, 0.517, 0.518, 0.519,\n",
      "       0.52 , 0.521, 0.522, 0.523, 0.524, 0.525, 0.526, 0.528, 0.529,\n",
      "       0.53 , 0.531, 0.532, 0.533, 0.535, 0.536, 0.537, 0.538, 0.539,\n",
      "       0.54 , 0.541, 0.542, 0.543, 0.544, 0.545, 0.546, 0.547, 0.548,\n",
      "       0.549, 0.55 , 0.551, 0.552, 0.553, 0.554, 0.555, 0.556, 0.557,\n",
      "       0.558, 0.559, 0.56 , 0.563, 0.564, 0.565, 0.566, 0.567, 0.568,\n",
      "       0.57 , 0.571, 0.572, 0.573, 0.574, 0.575, 0.576, 0.577, 0.579,\n",
      "       0.58 , 0.583, 0.584, 0.585, 0.586, 0.587, 0.588, 0.59 , 0.591,\n",
      "       0.592, 0.593, 0.594, 0.597, 0.598, 0.6  , 0.601, 0.602, 0.603,\n",
      "       0.604, 0.605, 0.606, 0.607, 0.608, 0.61 , 0.611, 0.615, 0.616,\n",
      "       0.619, 0.62 , 0.621, 0.623, 0.624, 0.625, 0.627, 0.628, 0.63 ,\n",
      "       0.631, 0.632, 0.635, 0.636, 0.637, 0.638, 0.643, 0.644, 0.645,\n",
      "       0.646, 0.648, 0.649, 0.65 , 0.652, 0.654, 0.655, 0.656, 0.657,\n",
      "       0.659, 0.66 , 0.661, 0.662, 0.663, 0.665, 0.666, 0.667, 0.67 ,\n",
      "       0.675, 0.678, 0.681, 0.683, 0.684, 0.686, 0.688, 0.689, 0.69 ,\n",
      "       0.692, 0.693, 0.7  , 0.705, 0.706, 0.71 , 0.711, 0.714, 0.716,\n",
      "       0.719, 0.72 , 0.722, 0.725, 0.727, 0.728, 0.733, 0.737, 0.738,\n",
      "       0.742, 0.745, 0.75 , 0.756, 0.759, 0.765, 0.769, 0.77 , 0.773,\n",
      "       0.775, 0.778, 0.78 , 0.783, 0.788, 0.789, 0.791, 0.792, 0.797,\n",
      "       0.798, 0.8  , 0.806, 0.811, 0.813, 0.816, 0.818, 0.82 , 0.822,\n",
      "       0.824, 0.826, 0.828, 0.829, 0.833, 0.837, 0.841, 0.845, 0.846,\n",
      "       0.847, 0.85 , 0.855, 0.857, 0.858, 0.864, 0.866, 0.867, 0.869,\n",
      "       0.872, 0.875, 0.882, 0.887, 0.889, 0.894, 0.897, 0.898, 0.899,\n",
      "       0.9  , 0.901, 0.902, 0.905, 0.907, 0.908, 0.909, 0.911, 0.912,\n",
      "       0.913, 0.915, 0.916, 0.917, 0.918, 0.92 , 0.921, 0.923, 0.924,\n",
      "       0.925, 0.926, 0.927, 0.929, 0.93 , 0.931, 0.933, 0.935, 0.938,\n",
      "       0.939, 0.941, 0.942, 0.943, 0.944, 0.945, 0.946, 0.949, 0.95 ,\n",
      "       0.952, 0.953, 0.955, 0.959, 0.96 , 0.961, 0.962, 0.963, 0.964,\n",
      "       0.967, 0.971, 0.972, 0.974, 0.975, 0.977, 0.98 , 0.981, 0.983,\n",
      "       0.984, 0.985, 0.986, 0.99 , 0.992, 0.993, 0.994, 0.998, 1.   ]), array([  3,   3,   1,   1,   1,   1,   3,   2,   1,   1,   2,   1,   1,\n",
      "         2,   2,   2,   1,   2,   4,   2,   3,   3,   3,   3,   4,   4,\n",
      "         3,   1,   2,   4,   3,   2,   2,   1,   2,   4,   2,   1,   2,\n",
      "         2,   1,   1,   4,   2,   3,   5,   3,   3,   2,   3,   2,   2,\n",
      "         2,   4,   4,   4,   2,   6,   2,   8,   3,   1,   7,   3,   5,\n",
      "         2,   1,   5,   4,   2,   6,   4,   5,   7,  11,   8,   2,   3,\n",
      "         2,   4,   4,   4,   3,   3,   1,  13,   4,  12,   5,   7,   7,\n",
      "        15,   5,   3,  11,   8,   5,   4,   7,  11,   9,   7,   8,   3,\n",
      "         9,   9,   9,   4,   6,  10,   8,   5,   4,   5,  15,  14,   8,\n",
      "        10,  12,  14,  13,   4,  13,  12,   7,   6,   7,   9,   8,  18,\n",
      "         8,  24,   3,   8,  12,   5,   7,  10,  13,  13,  12,  10,  13,\n",
      "         6,  14,  10,  13,   6,   9,  11,  11,   5,  12,  15,   8,   8,\n",
      "        11,  12,   8,   7,  10,   6,  11,  17,   9,  21,  10,  11,  10,\n",
      "        16,  13,  11,  10,  12,   9,  11,  14,  10,  13,  10,   9,  34,\n",
      "        11,  11,  12,  13,  13,  15,  22,  14,  23,  12,  16,  15,  11,\n",
      "        17,  21,  13,  23,  25,  17,  17,  11,  11,  21,  16,  15,  13,\n",
      "        12,  22,  18,  14,  19,  21,  13,   9,  12,  58,   9,  13,  10,\n",
      "         9,   6,  28,  19,  25,  22,  20,  16,  24,  16,  33,  11,  24,\n",
      "        17,  15,  10,  27,  18,  23,  15,  17,  11,  15,  21,  19,   9,\n",
      "        20,  18,  22,  19,  16,  25,  11,  14,  20,  15,  14,  23,  15,\n",
      "        27,  20,  11,  11,  52,   9,  14,  18,  24,  18,  24,  12,  12,\n",
      "        16,  20,  21,  12,  14,  17,  13,  15,  26,  19,  15,  14,  19,\n",
      "        14,  26,  38,  11,  15,  25,  24,  14,  22,  24,  20,  11,  22,\n",
      "         9,  10,  19,  27,   8,  13,  11,  53,  14,  18,  19,  15,  16,\n",
      "        20,  12,  17,   8,  21,  11,   4,  19,  15,  13,  11,  16,  20,\n",
      "        11,  11,  19,   8,  17,   8,  38,   6,  11,  17,   9,  13,  21,\n",
      "        17,  10,   8,   9,  15,  10,  11,   7,  12,   6,  27,   3,   9,\n",
      "        11,   5,   5,  10,   8,  20,  12,  13,   7,  26,   6,   8,   8,\n",
      "        15,   8,   6,   9,   1,  22,   5,   3,   5,   9,   8,  16,   5,\n",
      "         6,   6,   6,   7,  13,   6,  13,   7,   8,  11,  16,   6,  19,\n",
      "         2,   9,   8,   7,   9,  16,  10,   6,  12,   6,  11,   3,   6,\n",
      "         7,   5,   3,  10,   7,   7,   2,   8,   3,   7,   8,   5,   4,\n",
      "         8,   7,   5,   3,   1,   7,  10,   9,   1,   6,   2,   3,   2,\n",
      "         2,   2,  37,   3,   2,   2,   5,   6,   5,   2,   5,   4,   4,\n",
      "         1,   1,   4,   2,   6,   2,   3,   6,   7,   3,   3,   6,   2,\n",
      "         5,   3,   4,   5,   2,   3,   3,   6,   2,   7,   7,   9,   1,\n",
      "         5,   1,   7,   4,   2,   4,   1,   2,   4,   2,  11,   2,   1,\n",
      "         3,   2,   2,   7,   2,   1,   1,   6,   5,   6,   1,   3,   1,\n",
      "         6,   2,   8,   1,   1,   1,   2,   3,   2,   4,   4,  14,   2,\n",
      "         1,   4,   7,   2,   2,   2,   3,   1,   3,   1,   3,  16,   1,\n",
      "         3,   2,   2,   3,   1,   1,   4,   1,   5,   3,   2,   2,   2,\n",
      "         3,   3,   1,   4,   1,   2,   4,   1,   2,   2,   1,   1,   1,\n",
      "         5,   1,   1,   3,   2,   1,   1,   1,   1,   2,   2,   2,   1,\n",
      "         1,   2,   2,   1,   1,   1,  14,   1,   5,   1,   1,   2,   1,\n",
      "         2,   1,   3,   1,   2,   1,   5,   4,   2,   1,   1,   4,   1,\n",
      "         1,   1,   3,   1,   4,   1,   1,   1,   1,   1,   1,   5,   1,\n",
      "         1,   2,   1,   1,   1,   1,   8,   3,   1,   1,   1,   1,   1,\n",
      "         1,   1,   5,   1,   1,   1,   2,   1,   1,   1,   1,   1,   1,\n",
      "         2,   1,   1,   1,   1,   2,   1,   1,   1,   3,   1,   1,   1,\n",
      "         2,   2,   1,   7,   2,   1,   6,   1,   1,   1,   1,   4,   1,\n",
      "         1,   2,   2,   1,   2,   2,   1,   1,   1,   1,   4,   1,   2,\n",
      "         2,   1,   2,   1,   1,   3,   3,   1,   2,   1,   1,   1,   2,\n",
      "         3,   1,   1,   2,   2,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "         2,   1,   3,   2,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "         1,   1,   1,   2,   1,   3,   1,   1, 106], dtype=int64))\n",
      "(array([0.062, 0.066, 0.07 , 0.071, 0.089, 0.09 , 0.094, 0.095, 0.105,\n",
      "       0.109, 0.112, 0.121, 0.123, 0.128, 0.144, 0.156, 0.157, 0.16 ,\n",
      "       0.165, 0.17 , 0.173, 0.175, 0.179, 0.183, 0.193, 0.195, 0.197,\n",
      "       0.2  , 0.202, 0.204, 0.207, 0.215, 0.221, 0.224, 0.226, 0.233,\n",
      "       0.235, 0.238, 0.245, 0.248, 0.254, 0.255, 0.257, 0.258, 0.259,\n",
      "       0.264, 0.267, 0.268, 0.269, 0.271, 0.273, 0.276, 0.285, 0.286,\n",
      "       0.288, 0.289, 0.292, 0.294, 0.295, 0.296, 0.298, 0.301, 0.303,\n",
      "       0.304, 0.305, 0.308, 0.314, 0.317, 0.318, 0.319, 0.323, 0.326,\n",
      "       0.328, 0.332, 0.333, 0.337, 0.338, 0.339, 0.34 , 0.342, 0.343,\n",
      "       0.344, 0.345, 0.346, 0.347, 0.353, 0.357, 0.358, 0.359, 0.363,\n",
      "       0.364, 0.365, 0.368, 0.369, 0.371, 0.373, 0.374, 0.375, 0.377,\n",
      "       0.378, 0.379, 0.381, 0.382, 0.383, 0.384, 0.385, 0.386, 0.387,\n",
      "       0.388, 0.389, 0.39 , 0.392, 0.393, 0.394, 0.395, 0.396, 0.397,\n",
      "       0.398, 0.4  , 0.401, 0.402, 0.403, 0.405, 0.406, 0.408, 0.409,\n",
      "       0.41 , 0.412, 0.413, 0.414, 0.416, 0.417, 0.418, 0.42 , 0.421,\n",
      "       0.422, 0.424, 0.427, 0.428, 0.429, 0.43 , 0.431, 0.432, 0.433,\n",
      "       0.434, 0.435, 0.436, 0.437, 0.438, 0.439, 0.44 , 0.441, 0.444,\n",
      "       0.445, 0.446, 0.447, 0.449, 0.45 , 0.452, 0.453, 0.455, 0.456,\n",
      "       0.457, 0.458, 0.46 , 0.461, 0.462, 0.463, 0.464, 0.465, 0.466,\n",
      "       0.467, 0.468, 0.469, 0.47 , 0.471, 0.472, 0.473, 0.475, 0.476,\n",
      "       0.477, 0.478, 0.479, 0.48 , 0.481, 0.482, 0.483, 0.484, 0.485,\n",
      "       0.486, 0.487, 0.489, 0.49 , 0.491, 0.492, 0.493, 0.494, 0.495,\n",
      "       0.496, 0.497, 0.498, 0.5  , 0.501, 0.502, 0.503, 0.504, 0.505,\n",
      "       0.507, 0.508, 0.509, 0.51 , 0.511, 0.512, 0.513, 0.514, 0.515,\n",
      "       0.516, 0.517, 0.518, 0.519, 0.52 , 0.521, 0.522, 0.523, 0.524,\n",
      "       0.526, 0.527, 0.528, 0.529, 0.53 , 0.531, 0.532, 0.533, 0.534,\n",
      "       0.535, 0.536, 0.537, 0.538, 0.539, 0.54 , 0.541, 0.542, 0.543,\n",
      "       0.544, 0.545, 0.546, 0.547, 0.548, 0.549, 0.55 , 0.551, 0.552,\n",
      "       0.553, 0.554, 0.555, 0.556, 0.557, 0.558, 0.559, 0.56 , 0.561,\n",
      "       0.562, 0.563, 0.564, 0.565, 0.566, 0.567, 0.568, 0.569, 0.57 ,\n",
      "       0.571, 0.572, 0.573, 0.574, 0.575, 0.576, 0.577, 0.578, 0.579,\n",
      "       0.58 , 0.581, 0.582, 0.583, 0.584, 0.585, 0.586, 0.587, 0.588,\n",
      "       0.589, 0.59 , 0.591, 0.592, 0.593, 0.594, 0.595, 0.596, 0.597,\n",
      "       0.598, 0.599, 0.6  , 0.601, 0.602, 0.603, 0.604, 0.605, 0.606,\n",
      "       0.607, 0.608, 0.609, 0.61 , 0.611, 0.612, 0.613, 0.614, 0.615,\n",
      "       0.616, 0.617, 0.618, 0.619, 0.62 , 0.621, 0.622, 0.623, 0.624,\n",
      "       0.625, 0.626, 0.627, 0.628, 0.629, 0.63 , 0.631, 0.632, 0.633,\n",
      "       0.634, 0.635, 0.636, 0.637, 0.638, 0.639, 0.64 , 0.641, 0.642,\n",
      "       0.643, 0.644, 0.645, 0.646, 0.647, 0.648, 0.649, 0.65 , 0.651,\n",
      "       0.652, 0.653, 0.654, 0.655, 0.656, 0.657, 0.658, 0.659, 0.66 ,\n",
      "       0.661, 0.662, 0.663, 0.664, 0.665, 0.666, 0.667, 0.668, 0.669,\n",
      "       0.67 , 0.671, 0.672, 0.673, 0.674, 0.675, 0.676, 0.677, 0.678,\n",
      "       0.679, 0.68 , 0.681, 0.682, 0.683, 0.684, 0.685, 0.686, 0.687,\n",
      "       0.688, 0.689, 0.69 , 0.691, 0.692, 0.693, 0.694, 0.695, 0.696,\n",
      "       0.697, 0.698, 0.699, 0.7  , 0.701, 0.702, 0.703, 0.704, 0.705,\n",
      "       0.706, 0.707, 0.708, 0.709, 0.71 , 0.711, 0.712, 0.713, 0.714,\n",
      "       0.715, 0.716, 0.717, 0.718, 0.719, 0.72 , 0.721, 0.722, 0.723,\n",
      "       0.724, 0.725, 0.726, 0.727, 0.728, 0.729, 0.73 , 0.731, 0.732,\n",
      "       0.733, 0.734, 0.735, 0.736, 0.737, 0.738, 0.739, 0.74 , 0.741,\n",
      "       0.742, 0.743, 0.744, 0.745, 0.746, 0.747, 0.748, 0.749, 0.75 ,\n",
      "       0.751, 0.752, 0.753, 0.754, 0.755, 0.756, 0.757, 0.758, 0.759,\n",
      "       0.76 , 0.761, 0.762, 0.763, 0.764, 0.765, 0.766, 0.767, 0.768,\n",
      "       0.769, 0.77 , 0.771, 0.772, 0.773, 0.774, 0.775, 0.776, 0.777,\n",
      "       0.778, 0.779, 0.78 , 0.781, 0.782, 0.783, 0.784, 0.785, 0.786,\n",
      "       0.787, 0.788, 0.789, 0.79 , 0.791, 0.792, 0.793, 0.794, 0.795,\n",
      "       0.796, 0.797, 0.798, 0.799, 0.8  , 0.801, 0.802, 0.803, 0.804,\n",
      "       0.805, 0.806, 0.807, 0.808, 0.809, 0.81 , 0.811, 0.812, 0.813,\n",
      "       0.814, 0.815, 0.816, 0.817, 0.818, 0.819, 0.82 , 0.821, 0.822,\n",
      "       0.823, 0.824, 0.825, 0.826, 0.827, 0.828, 0.829, 0.83 , 0.831,\n",
      "       0.832, 0.833, 0.834, 0.835, 0.836, 0.837, 0.838, 0.839, 0.84 ,\n",
      "       0.841, 0.842, 0.843, 0.844, 0.845, 0.846, 0.847, 0.848, 0.849,\n",
      "       0.85 , 0.851, 0.852, 0.853, 0.854, 0.855, 0.856, 0.857, 0.858,\n",
      "       0.859, 0.86 , 0.861, 0.862, 0.863, 0.864, 0.865, 0.866, 0.867,\n",
      "       0.868, 0.869, 0.87 , 0.871, 0.872, 0.873, 0.874, 0.875, 0.876,\n",
      "       0.877, 0.878, 0.879, 0.88 , 0.881, 0.882, 0.883, 0.884, 0.885,\n",
      "       0.886, 0.887, 0.888, 0.889, 0.89 , 0.891, 0.892, 0.893, 0.894,\n",
      "       0.895, 0.896, 0.897, 0.898, 0.899, 0.9  , 0.901, 0.902, 0.903,\n",
      "       0.904, 0.905, 0.906, 0.907, 0.908, 0.909, 0.91 , 0.911, 0.912,\n",
      "       0.913, 0.914, 0.915, 0.916, 0.917, 0.918, 0.919, 0.92 , 0.921,\n",
      "       0.922, 0.923, 0.924, 0.925, 0.926, 0.927, 0.928, 0.929, 0.93 ,\n",
      "       0.931, 0.932, 0.933, 0.934, 0.935, 0.936, 0.937, 0.938, 0.939,\n",
      "       0.94 , 0.941, 0.942, 0.943, 0.944, 0.945, 0.946, 0.947, 0.948,\n",
      "       0.949, 0.95 , 0.951, 0.952, 0.953, 0.954, 0.955, 0.956, 0.957,\n",
      "       0.958, 0.959, 0.96 , 0.961, 0.962, 0.963, 0.964, 0.965, 0.966,\n",
      "       0.967, 0.968, 0.969, 0.97 , 0.971, 0.972, 0.973, 0.974, 0.975,\n",
      "       0.976, 0.977, 0.978, 0.979, 0.98 , 0.981, 0.982, 0.983, 0.984,\n",
      "       0.985, 0.986, 0.987, 0.988, 0.989, 0.99 , 0.991, 0.992, 0.993,\n",
      "       0.994, 0.995, 0.996, 0.997, 0.998, 0.999, 1.   ]), array([  1,   1,   1,   1,   1,   1,   1,   2,   1,   1,   1,   1,   1,\n",
      "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "         3,   2,   1,   1,   1,   1,   1,   1,   2,   1,   1,   2,   1,\n",
      "         1,   2,   1,   1,   1,   1,   1,   2,   1,   1,   1,   1,   2,\n",
      "         2,   1,   2,   1,   2,   1,   2,   1,   1,   1,   1,   2,   1,\n",
      "         1,   1,   2,   3,   2,   1,   1,   1,   1,   2,   2,   1,   2,\n",
      "         1,   1,   1,   2,   1,   1,   3,   2,   1,   2,   1,   2,   1,\n",
      "         2,   1,   1,   2,   1,   1,   2,   1,   1,   1,   2,   1,   1,\n",
      "         1,   5,   2,   1,   1,   2,   3,   1,   1,   1,   1,   1,   1,\n",
      "         1,   5,   1,   1,   1,   1,   1,   1,   1,   4,   1,   1,   1,\n",
      "         3,   2,   1,   1,   2,   1,   1,   2,   1,   4,   1,   1,   1,\n",
      "         2,   4,   2,   1,   1,   3,   3,   3,   2,   1,   1,   1,   1,\n",
      "         1,   2,   1,   3,   2,   1,   3,   2,   1,   2,   1,   3,   1,\n",
      "         3,   3,   3,   1,   4,   3,   1,   1,   4,   1,   2,   2,   1,\n",
      "         2,   3,   1,   6,   2,   3,  12,   2,   4,   1,   4,   1,   2,\n",
      "         3,   3,   6,   3,   1,   2,   4,   6,   3,   4,   2,   5,   2,\n",
      "         3,   3,   2,   3,   4,   6,   6,   7,   4,   8,   3,   5,   5,\n",
      "         3,   6,   3,   5,   2,   5,   3,   7,   2,   3,   3,   1,   2,\n",
      "         8,   4,   4,   3,   2,   3,   5,   5,   8,   5,   7,   6,   5,\n",
      "         3,   2,   6,   7,   7,   3,   5,   3,   4,   6,  10,   6,   4,\n",
      "         7,   4,   5,   9,   6,   5,   7,   3,   7,   9,   6,   3,   4,\n",
      "         2,   5,   9,   7,   5,   8,   4,   9,   7,   7,   5,   5,   2,\n",
      "        17,   6,  10,  12,   7,  10,   6,  10,   7,   3,   7,   9,   7,\n",
      "         6,  10,   7,   4,   8,   4,   8,   6,   5,   6,   6,   5,   8,\n",
      "        11,  10,   9,   4,   5,   4,   8,   7,   8,   3,   6,   8,   3,\n",
      "         9,   1,   7,   5,  13,   8,   7,   4,   5,   8,  12,  13,   5,\n",
      "        10,   7,   7,   6,  11,   9,   6,   7,   5,   9,  12,   2,  10,\n",
      "         5,   3,  25,   4,   5,   8,  11,  11,   9,   7,  10,   7,  16,\n",
      "         7,  10,  10,  10,   4,  12,   9,   8,  12,  10,  18,  13,  10,\n",
      "         9,   9,   9,  14,  12,   7,  10,  12,   4,  13,   6,   3,  11,\n",
      "         8,  14,  11,  10,  13,   9,  10,  11,   8,  11,  16,   2,   5,\n",
      "        11,   7,  10,  10,   8,  13,   8,  12,   9,   7,  15,   7,   8,\n",
      "        16,  13,   4,  15,  12,  10,   8,  13,  15,   9,  10,  11,  14,\n",
      "        12,  15,  15,  11,  14,  12,   3,  29,  12,  10,  11,   4,   7,\n",
      "        12,  15,   9,  13,   9,   5,  11,   8,  14,  11,   5,  11,  22,\n",
      "         8,  11,  15,  10,  10,  13,  10,   4,   7,  34,  10,  13,  18,\n",
      "         7,  15,  11,   4,  29,   8,  12,  17,  13,  11,  23,   3,   6,\n",
      "        16,   7,   7,  14,   6,  24,   6,   9,  13,  17,   5,   8,   8,\n",
      "        18,   3,  12,  12,   5,  20,  11,   8,  11,  16,  20,   8,   4,\n",
      "        10,   5,   6,  10,  10,  13,   9,   5,  16,  13,  13,   9,  19,\n",
      "         6,  13,   6,   7,  13,  10,   6,  14,  12,  12,  18,   9,  16,\n",
      "        10,  15,  12,  20,   8,  15,   8,   3,   6,  12,  28,   6,   6,\n",
      "        11,  10,   9,  14,  10,   9,   6,  17,  10,   8,  13,  11,  18,\n",
      "        10,  11,  23,   9,   8,  10,  10,  17,  14,  12,  10,  10,  11,\n",
      "        23,   5,  11,  24,   7,  13,   3,   8,   4,  15,  17,  13,  13,\n",
      "         9,  16,  11,   5,  10,   7,   8,  10,  10,  14,  16,  13,  10,\n",
      "        10,  14,  14,   8,   5,  18,  10,   3,  10,   6,  14,  11,   8,\n",
      "        14,   5,  21,   2,  20,   9,   8,   6,  21,   8,  11,   7,  15,\n",
      "        21,  19,   8,   6,  11,   8,  16,   8,   7,  15,  12,   3,  11,\n",
      "         8,  16,   9,  12,  17,  11,   9,  23,   9,  10,  16,   6,   7,\n",
      "        13,   6,  11,  10,   5,  16,  11,  12,   4,   8,  16,  10,  12,\n",
      "         6,   9,   9,  12,  13,   7,   8,   7,   3,   9,   7,  10,   7,\n",
      "         9,  16,   7,   7,   5,   3,   8,   7,   4,   3, 639], dtype=int64))\n",
      "(array([1.0000e+00, 1.0200e+00, 1.0300e+00, 1.0400e+00, 1.0500e+00,\n",
      "       1.0600e+00, 1.0700e+00, 1.0800e+00, 1.0900e+00, 1.1100e+00,\n",
      "       1.1200e+00, 1.1300e+00, 1.1400e+00, 1.1500e+00, 1.1600e+00,\n",
      "       1.1700e+00, 1.1800e+00, 1.1900e+00, 1.2000e+00, 1.2100e+00,\n",
      "       1.2200e+00, 1.2300e+00, 1.2400e+00, 1.2500e+00, 1.2600e+00,\n",
      "       1.2700e+00, 1.2800e+00, 1.2900e+00, 1.3000e+00, 1.3100e+00,\n",
      "       1.3200e+00, 1.3300e+00, 1.3400e+00, 1.3500e+00, 1.3600e+00,\n",
      "       1.3700e+00, 1.3800e+00, 1.3900e+00, 1.4000e+00, 1.4100e+00,\n",
      "       1.4200e+00, 1.4300e+00, 1.4400e+00, 1.4500e+00, 1.4600e+00,\n",
      "       1.4700e+00, 1.4800e+00, 1.4900e+00, 1.5000e+00, 1.5100e+00,\n",
      "       1.5200e+00, 1.5300e+00, 1.5400e+00, 1.5500e+00, 1.5600e+00,\n",
      "       1.5700e+00, 1.5800e+00, 1.5900e+00, 1.6000e+00, 1.6100e+00,\n",
      "       1.6200e+00, 1.6300e+00, 1.6400e+00, 1.6500e+00, 1.6600e+00,\n",
      "       1.6700e+00, 1.6800e+00, 1.6900e+00, 1.7000e+00, 1.7100e+00,\n",
      "       1.7200e+00, 1.7300e+00, 1.7400e+00, 1.7500e+00, 1.7600e+00,\n",
      "       1.7700e+00, 1.7800e+00, 1.7900e+00, 1.8000e+00, 1.8100e+00,\n",
      "       1.8200e+00, 1.8300e+00, 1.8400e+00, 1.8500e+00, 1.8600e+00,\n",
      "       1.8700e+00, 1.8800e+00, 1.8900e+00, 1.9000e+00, 1.9100e+00,\n",
      "       1.9200e+00, 1.9300e+00, 1.9400e+00, 1.9500e+00, 1.9600e+00,\n",
      "       1.9700e+00, 1.9800e+00, 1.9900e+00, 2.0000e+00, 2.0100e+00,\n",
      "       2.0200e+00, 2.0300e+00, 2.0400e+00, 2.0500e+00, 2.0600e+00,\n",
      "       2.0700e+00, 2.0800e+00, 2.0900e+00, 2.1000e+00, 2.1100e+00,\n",
      "       2.1200e+00, 2.1300e+00, 2.1400e+00, 2.1500e+00, 2.1600e+00,\n",
      "       2.1700e+00, 2.1800e+00, 2.1900e+00, 2.2000e+00, 2.2100e+00,\n",
      "       2.2200e+00, 2.2300e+00, 2.2400e+00, 2.2500e+00, 2.2600e+00,\n",
      "       2.2700e+00, 2.2800e+00, 2.2900e+00, 2.3000e+00, 2.3100e+00,\n",
      "       2.3200e+00, 2.3300e+00, 2.3400e+00, 2.3500e+00, 2.3600e+00,\n",
      "       2.3700e+00, 2.3800e+00, 2.3900e+00, 2.4000e+00, 2.4100e+00,\n",
      "       2.4200e+00, 2.4300e+00, 2.4400e+00, 2.4500e+00, 2.4600e+00,\n",
      "       2.4700e+00, 2.4800e+00, 2.4900e+00, 2.5000e+00, 2.5100e+00,\n",
      "       2.5200e+00, 2.5300e+00, 2.5400e+00, 2.5500e+00, 2.5600e+00,\n",
      "       2.5700e+00, 2.5800e+00, 2.5900e+00, 2.6000e+00, 2.6100e+00,\n",
      "       2.6200e+00, 2.6300e+00, 2.6400e+00, 2.6500e+00, 2.6600e+00,\n",
      "       2.6700e+00, 2.6800e+00, 2.6900e+00, 2.7000e+00, 2.7100e+00,\n",
      "       2.7200e+00, 2.7300e+00, 2.7400e+00, 2.7500e+00, 2.7600e+00,\n",
      "       2.7700e+00, 2.7800e+00, 2.7900e+00, 2.8000e+00, 2.8100e+00,\n",
      "       2.8200e+00, 2.8300e+00, 2.8400e+00, 2.8500e+00, 2.8600e+00,\n",
      "       2.8700e+00, 2.8800e+00, 2.8900e+00, 2.9000e+00, 2.9100e+00,\n",
      "       2.9200e+00, 2.9300e+00, 2.9400e+00, 2.9500e+00, 2.9600e+00,\n",
      "       2.9700e+00, 2.9800e+00, 2.9900e+00, 3.0000e+00, 3.0100e+00,\n",
      "       3.0200e+00, 3.0300e+00, 3.0400e+00, 3.0500e+00, 3.0700e+00,\n",
      "       3.0800e+00, 3.0900e+00, 3.1000e+00, 3.1100e+00, 3.1200e+00,\n",
      "       3.1300e+00, 3.1400e+00, 3.1500e+00, 3.1600e+00, 3.1700e+00,\n",
      "       3.1800e+00, 3.1900e+00, 3.2000e+00, 3.2100e+00, 3.2200e+00,\n",
      "       3.2300e+00, 3.2400e+00, 3.2500e+00, 3.2600e+00, 3.2700e+00,\n",
      "       3.2800e+00, 3.2900e+00, 3.3000e+00, 3.3100e+00, 3.3200e+00,\n",
      "       3.3300e+00, 3.3400e+00, 3.3500e+00, 3.3600e+00, 3.3800e+00,\n",
      "       3.4000e+00, 3.4100e+00, 3.4200e+00, 3.4300e+00, 3.4400e+00,\n",
      "       3.4500e+00, 3.4600e+00, 3.4800e+00, 3.4900e+00, 3.5000e+00,\n",
      "       3.5100e+00, 3.5200e+00, 3.5300e+00, 3.5400e+00, 3.5600e+00,\n",
      "       3.5700e+00, 3.5800e+00, 3.5900e+00, 3.6000e+00, 3.6100e+00,\n",
      "       3.6200e+00, 3.6300e+00, 3.6700e+00, 3.6800e+00, 3.7100e+00,\n",
      "       3.7200e+00, 3.7500e+00, 3.7600e+00, 3.8000e+00, 3.8100e+00,\n",
      "       3.8300e+00, 3.8500e+00, 3.8600e+00, 3.8700e+00, 3.8800e+00,\n",
      "       3.8900e+00, 3.9100e+00, 3.9200e+00, 3.9300e+00, 3.9600e+00,\n",
      "       4.0000e+00, 4.0400e+00, 4.0500e+00, 4.0800e+00, 4.1300e+00,\n",
      "       4.1400e+00, 4.1500e+00, 4.1600e+00, 4.1700e+00, 4.1800e+00,\n",
      "       4.2000e+00, 4.2200e+00, 4.2300e+00, 4.2500e+00, 4.2600e+00,\n",
      "       4.2700e+00, 4.2800e+00, 4.2900e+00, 4.3000e+00, 4.3200e+00,\n",
      "       4.3300e+00, 4.3500e+00, 4.3600e+00, 4.3800e+00, 4.3900e+00,\n",
      "       4.4000e+00, 4.4100e+00, 4.4300e+00, 4.4400e+00, 4.4500e+00,\n",
      "       4.4600e+00, 4.4700e+00, 4.4800e+00, 4.4900e+00, 4.5000e+00,\n",
      "       4.5100e+00, 4.5200e+00, 4.5300e+00, 4.5400e+00, 4.5500e+00,\n",
      "       4.5600e+00, 4.5700e+00, 4.5800e+00, 4.5900e+00, 4.6000e+00,\n",
      "       4.6100e+00, 4.6200e+00, 4.6300e+00, 4.6400e+00, 4.6500e+00,\n",
      "       4.6600e+00, 4.6700e+00, 4.6800e+00, 4.6900e+00, 4.7000e+00,\n",
      "       4.7100e+00, 4.7200e+00, 4.7300e+00, 4.7500e+00, 4.7700e+00,\n",
      "       4.7800e+00, 4.7900e+00, 4.8000e+00, 4.8100e+00, 4.8200e+00,\n",
      "       4.8300e+00, 4.8400e+00, 4.8500e+00, 4.8600e+00, 4.8700e+00,\n",
      "       4.8800e+00, 4.8900e+00, 4.9000e+00, 4.9200e+00, 4.9700e+00,\n",
      "       4.9800e+00, 4.9900e+00, 5.0000e+00, 5.0400e+00, 5.0500e+00,\n",
      "       5.0600e+00, 5.0700e+00, 5.0800e+00, 5.0900e+00, 5.1000e+00,\n",
      "       5.1300e+00, 5.1500e+00, 5.1600e+00, 5.1700e+00, 5.1800e+00,\n",
      "       5.1900e+00, 5.2000e+00, 5.2200e+00, 5.2300e+00, 5.2500e+00,\n",
      "       5.2600e+00, 5.2800e+00, 5.2900e+00, 5.3000e+00, 5.3200e+00,\n",
      "       5.3300e+00, 5.3400e+00, 5.3500e+00, 5.3600e+00, 5.3800e+00,\n",
      "       5.4000e+00, 5.4100e+00, 5.4300e+00, 5.4500e+00, 5.4600e+00,\n",
      "       5.5000e+00, 5.5100e+00, 5.5400e+00, 5.5500e+00, 5.5600e+00,\n",
      "       5.5700e+00, 5.6000e+00, 5.6700e+00, 5.6900e+00, 5.7300e+00,\n",
      "       5.7400e+00, 5.7500e+00, 5.7600e+00, 5.7800e+00, 5.8000e+00,\n",
      "       5.8400e+00, 5.8600e+00, 5.8800e+00, 5.8900e+00, 5.9000e+00,\n",
      "       5.9100e+00, 5.9300e+00, 5.9500e+00, 5.9600e+00, 5.9700e+00,\n",
      "       6.0000e+00, 6.0200e+00, 6.0400e+00, 6.0700e+00, 6.1100e+00,\n",
      "       6.1200e+00, 6.1300e+00, 6.1700e+00, 6.1900e+00, 6.2000e+00,\n",
      "       6.2200e+00, 6.2700e+00, 6.3000e+00, 6.3100e+00, 6.3200e+00,\n",
      "       6.3300e+00, 6.3400e+00, 6.3500e+00, 6.4000e+00, 6.4200e+00,\n",
      "       6.4400e+00, 6.4700e+00, 6.5000e+00, 6.5300e+00, 6.5500e+00,\n",
      "       6.5600e+00, 6.6000e+00, 6.6100e+00, 6.6300e+00, 6.6400e+00,\n",
      "       6.6700e+00, 6.7300e+00, 6.7700e+00, 6.8300e+00, 6.8500e+00,\n",
      "       6.8600e+00, 6.9000e+00, 6.9300e+00, 6.9400e+00, 7.0000e+00,\n",
      "       7.0200e+00, 7.0500e+00, 7.0900e+00, 7.1000e+00, 7.1300e+00,\n",
      "       7.1500e+00, 7.1600e+00, 7.2000e+00, 7.2100e+00, 7.2300e+00,\n",
      "       7.2400e+00, 7.2500e+00, 7.2700e+00, 7.2800e+00, 7.2900e+00,\n",
      "       7.3300e+00, 7.3400e+00, 7.3500e+00, 7.3600e+00, 7.3800e+00,\n",
      "       7.3900e+00, 7.4000e+00, 7.4200e+00, 7.4300e+00, 7.4700e+00,\n",
      "       7.4900e+00, 7.5000e+00, 7.5100e+00, 7.5500e+00, 7.5600e+00,\n",
      "       7.5700e+00, 7.5800e+00, 7.6000e+00, 7.6200e+00, 7.6300e+00,\n",
      "       7.6400e+00, 7.6500e+00, 7.6600e+00, 7.6700e+00, 7.6800e+00,\n",
      "       7.6900e+00, 7.7000e+00, 7.7200e+00, 7.7500e+00, 7.7600e+00,\n",
      "       7.7700e+00, 7.7800e+00, 7.8000e+00, 7.8200e+00, 7.8300e+00,\n",
      "       7.8400e+00, 7.8500e+00, 7.8600e+00, 7.8700e+00, 7.8800e+00,\n",
      "       7.8900e+00, 7.9000e+00, 7.9500e+00, 8.0000e+00, 8.0200e+00,\n",
      "       8.0500e+00, 8.0600e+00, 8.0700e+00, 8.1000e+00, 8.1100e+00,\n",
      "       8.1300e+00, 8.1400e+00, 8.1600e+00, 8.1900e+00, 8.2100e+00,\n",
      "       8.2200e+00, 8.2300e+00, 8.2400e+00, 8.2500e+00, 8.2700e+00,\n",
      "       8.2900e+00, 8.3500e+00, 8.3600e+00, 8.4000e+00, 8.4300e+00,\n",
      "       8.4500e+00, 8.4700e+00, 8.5000e+00, 8.5500e+00, 8.5700e+00,\n",
      "       8.5900e+00, 8.6200e+00, 8.6400e+00, 8.6700e+00, 8.6900e+00,\n",
      "       8.7200e+00, 8.7500e+00, 8.7700e+00, 8.8000e+00, 8.8200e+00,\n",
      "       8.8500e+00, 8.8600e+00, 8.9000e+00, 8.9200e+00, 8.9300e+00,\n",
      "       8.9400e+00, 9.0000e+00, 9.0600e+00, 9.1700e+00, 9.2000e+00,\n",
      "       9.2100e+00, 9.2500e+00, 9.3200e+00, 9.4000e+00, 9.4400e+00,\n",
      "       9.5000e+00, 9.6500e+00, 9.6700e+00, 9.7500e+00, 9.8000e+00,\n",
      "       9.8200e+00, 9.9000e+00, 9.9400e+00, 9.9500e+00, 1.0000e+01,\n",
      "       1.0040e+01, 1.0130e+01, 1.0170e+01, 1.0250e+01, 1.0270e+01,\n",
      "       1.0290e+01, 1.0330e+01, 1.0380e+01, 1.0430e+01, 1.0500e+01,\n",
      "       1.0590e+01, 1.0670e+01, 1.0750e+01, 1.0840e+01, 1.0860e+01,\n",
      "       1.0900e+01, 1.0990e+01, 1.1000e+01, 1.1200e+01, 1.1250e+01,\n",
      "       1.1280e+01, 1.1360e+01, 1.1500e+01, 1.1520e+01, 1.1540e+01,\n",
      "       1.1550e+01, 1.1570e+01, 1.1640e+01, 1.1670e+01, 1.1750e+01,\n",
      "       1.1800e+01, 1.1840e+01, 1.1880e+01, 1.1940e+01, 1.2000e+01,\n",
      "       1.2070e+01, 1.2080e+01, 1.2250e+01, 1.2290e+01, 1.2500e+01,\n",
      "       1.2530e+01, 1.2670e+01, 1.2820e+01, 1.2970e+01, 1.2990e+01,\n",
      "       1.3000e+01, 1.3040e+01, 1.3060e+01, 1.3070e+01, 1.3290e+01,\n",
      "       1.3500e+01, 1.3670e+01, 1.3680e+01, 1.3700e+01, 1.3900e+01,\n",
      "       1.4000e+01, 1.4190e+01, 1.4300e+01, 1.4500e+01, 1.4530e+01,\n",
      "       1.4880e+01, 1.4930e+01, 1.5000e+01, 1.5110e+01, 1.5170e+01,\n",
      "       1.5200e+01, 1.5220e+01, 1.5330e+01, 1.5500e+01, 1.5640e+01,\n",
      "       1.5670e+01, 1.5690e+01, 1.5800e+01, 1.5840e+01, 1.5900e+01,\n",
      "       1.5910e+01, 1.5940e+01, 1.6000e+01, 1.6120e+01, 1.6330e+01,\n",
      "       1.6570e+01, 1.6630e+01, 1.6640e+01, 1.6660e+01, 1.6680e+01,\n",
      "       1.6760e+01, 1.6830e+01, 1.6870e+01, 1.6880e+01, 1.6890e+01,\n",
      "       1.6910e+01, 1.7000e+01, 1.7040e+01, 1.7080e+01, 1.7120e+01,\n",
      "       1.7210e+01, 1.7270e+01, 1.7440e+01, 1.7510e+01, 1.7750e+01,\n",
      "       1.7820e+01, 1.7880e+01, 1.8000e+01, 1.8290e+01, 1.8340e+01,\n",
      "       1.8600e+01, 1.8670e+01, 1.8690e+01, 1.9000e+01, 1.9250e+01,\n",
      "       1.9280e+01, 1.9560e+01, 1.9600e+01, 1.9630e+01, 2.0000e+01,\n",
      "       2.0070e+01, 2.0660e+01, 2.0750e+01, 2.0760e+01, 2.1000e+01,\n",
      "       2.1150e+01, 2.1180e+01, 2.1270e+01, 2.1290e+01, 2.1300e+01,\n",
      "       2.1360e+01, 2.1400e+01, 2.1520e+01, 2.1660e+01, 2.2000e+01,\n",
      "       2.2110e+01, 2.2190e+01, 2.2240e+01, 2.2290e+01, 2.2500e+01,\n",
      "       2.3000e+01, 2.3620e+01, 2.4000e+01, 2.4290e+01, 2.4330e+01,\n",
      "       2.4360e+01, 2.4500e+01, 2.4670e+01, 2.4880e+01, 2.5000e+01,\n",
      "       2.5710e+01, 2.6000e+01, 2.6500e+01, 2.6570e+01, 2.6670e+01,\n",
      "       2.7000e+01, 2.7130e+01, 2.7150e+01, 2.8000e+01, 2.8640e+01,\n",
      "       2.8770e+01, 2.9000e+01, 2.9220e+01, 2.9290e+01, 2.9320e+01,\n",
      "       2.9780e+01, 3.0000e+01, 3.0250e+01, 3.0270e+01, 3.0370e+01,\n",
      "       3.0670e+01, 3.1000e+01, 3.2000e+01, 3.2110e+01, 3.2170e+01,\n",
      "       3.2670e+01, 3.2750e+01, 3.3000e+01, 3.3480e+01, 3.3500e+01,\n",
      "       3.3670e+01, 3.4000e+01, 3.4330e+01, 3.4880e+01, 3.5250e+01,\n",
      "       3.6000e+01, 3.6380e+01, 3.6500e+01, 3.6650e+01, 3.7000e+01,\n",
      "       3.7600e+01, 3.8000e+01, 3.8430e+01, 3.8650e+01, 3.9000e+01,\n",
      "       4.0000e+01, 4.0200e+01, 4.0330e+01, 4.0570e+01, 4.1080e+01,\n",
      "       4.2000e+01, 4.2170e+01, 4.3480e+01, 4.4370e+01, 4.4500e+01,\n",
      "       4.5000e+01, 4.6000e+01, 4.6500e+01, 4.6930e+01, 4.6950e+01,\n",
      "       4.7000e+01, 4.7330e+01, 4.9820e+01, 5.0000e+01, 5.0500e+01,\n",
      "       5.1000e+01, 5.1400e+01, 5.2000e+01, 5.3000e+01, 5.4000e+01,\n",
      "       5.5420e+01, 5.5500e+01, 5.6000e+01, 5.7000e+01, 5.8000e+01,\n",
      "       5.8500e+01, 5.9000e+01, 6.0830e+01, 6.1000e+01, 6.2000e+01,\n",
      "       6.2440e+01, 6.2810e+01, 6.3000e+01, 6.3750e+01, 6.4000e+01,\n",
      "       6.6000e+01, 6.7820e+01, 7.0000e+01, 7.1130e+01, 7.2380e+01,\n",
      "       7.2470e+01, 7.3000e+01, 7.6000e+01, 7.7500e+01, 8.2570e+01,\n",
      "       8.4000e+01, 8.7000e+01, 8.8500e+01, 8.8620e+01, 9.5000e+01,\n",
      "       9.5800e+01, 9.7000e+01, 1.0033e+02, 1.0495e+02, 1.1100e+02,\n",
      "       1.1389e+02, 1.1700e+02, 1.1780e+02, 1.2300e+02, 1.2500e+02,\n",
      "       1.2700e+02, 1.3500e+02, 1.3660e+02, 1.3750e+02, 1.3800e+02,\n",
      "       1.4050e+02, 1.4100e+02, 1.4836e+02, 1.5600e+02, 1.5800e+02,\n",
      "       1.6200e+02, 1.7900e+02, 1.8033e+02, 1.8133e+02, 1.8678e+02,\n",
      "       1.8979e+02, 1.9700e+02, 2.0400e+02, 2.0700e+02, 2.1400e+02,\n",
      "       2.4583e+02, 2.5700e+02, 2.7700e+02, 4.1200e+02, 5.3700e+02,\n",
      "       4.9550e+03]), array([ 3,  4,  5,  3,  6,  4, 11,  5,  4,  6,  1,  7,  8,  6,  3, 14, 12,\n",
      "       10, 15, 16, 15, 17, 20, 19, 30, 32, 33, 39, 27, 33, 32, 46, 30, 40,\n",
      "       47, 26, 59, 31, 51, 36, 33, 30, 31, 31, 35, 28, 32, 21, 43, 22, 27,\n",
      "       29, 27, 23, 27, 36, 35, 16, 32, 27, 17, 34, 34, 28, 26, 38, 25, 34,\n",
      "       22, 43, 16, 23, 24, 40, 28, 31, 25, 30, 27, 29, 31, 42, 33, 33, 30,\n",
      "       33, 34, 31, 27, 32, 26, 43, 32, 25, 20, 25, 27, 18, 93, 17, 18, 17,\n",
      "       14, 24, 24, 28, 27, 32, 32, 25, 13, 21, 33, 13, 14, 24, 24, 22, 41,\n",
      "       18, 32, 17, 16, 28, 11, 14, 11, 21, 22, 16, 10, 35, 13, 21, 12, 12,\n",
      "       22, 10, 23, 16, 17, 11, 29, 15, 13, 25, 10,  8, 22,  8,  9, 10,  6,\n",
      "        9, 16, 13, 17,  9, 13,  8,  6, 15, 11,  7,  2, 18,  8,  6, 15, 16,\n",
      "        7,  7, 14, 19,  6, 11, 15,  9, 10, 10,  9, 10,  7,  9, 12,  5, 11,\n",
      "        5,  8, 13,  9,  6,  8, 12,  4,  7,  7,  3, 42,  5,  6,  7,  6,  5,\n",
      "        6,  6,  4,  4,  9,  7,  5,  5,  4,  3,  6,  5,  1,  6,  4,  6,  4,\n",
      "        2,  7,  3,  2,  2,  4,  2,  5,  1,  4,  1,  3,  5,  5,  4,  1,  3,\n",
      "        2,  3,  2,  1,  5,  3, 18,  1,  2,  2,  3,  2,  1,  3,  2,  6,  1,\n",
      "        2,  1, 11,  1,  4,  2,  3,  1,  2,  1,  2,  2,  2,  1,  5,  2,  2,\n",
      "        1,  4,  3, 22,  1,  1,  4,  4,  1,  1,  1,  1,  1,  2,  1,  1,  4,\n",
      "        1,  1,  1,  3,  3,  1,  5,  1,  5,  3,  1,  1,  1,  1,  4,  1,  2,\n",
      "        1,  2,  1, 15,  2,  1,  3,  2,  2,  2,  1,  2,  1,  4,  2,  1,  1,\n",
      "        1,  2,  2, 10,  1,  3,  2,  5,  4,  1,  3,  1,  1,  3,  1,  5,  1,\n",
      "        1,  2,  1,  1,  2,  1,  2,  1,  2,  3,  1,  1, 17,  2,  2,  1,  1,\n",
      "        1,  1,  5,  1,  3,  2,  2,  1,  2,  2,  2,  1,  4,  1,  3,  3,  4,\n",
      "        1,  1,  3,  4,  1,  1,  1,  1,  1,  2,  1,  8,  1,  1,  2,  1,  3,\n",
      "        1,  2,  2,  1,  1,  6,  1,  1,  1,  1,  1,  2,  1,  1,  1,  1,  1,\n",
      "        1,  2,  7,  1,  1,  1,  1,  1,  1,  2,  2,  1,  2,  2,  1,  2,  1,\n",
      "        1,  1,  1,  4,  1,  1,  1,  7,  1,  1,  1,  1,  1,  3,  1,  3,  1,\n",
      "        1,  1,  1,  2,  1,  1,  3, 43,  2,  1,  1,  2,  1,  1,  1,  2,  2,\n",
      "        2,  2,  2,  1,  2,  2,  1,  1,  3,  2,  1,  1,  1,  2,  1,  1,  2,\n",
      "        5,  1,  2,  2,  2,  2,  3,  3,  1,  2,  1,  1,  2,  1,  1,  1,  1,\n",
      "        1,  1,  1,  1,  2,  1,  1,  1,  1,  3,  1,  1,  1,  2,  2, 37,  1,\n",
      "        2,  1,  2,  1,  1,  1,  2,  1,  1,  1,  1,  1,  1,  2,  1,  2,  1,\n",
      "        1,  2,  2,  1,  1,  3,  1,  1,  2,  1,  1,  1,  1,  1,  2,  1,  1,\n",
      "        2,  1,  2,  1,  1,  1,  1, 32,  1,  2,  2,  1,  1,  1,  3,  1,  1,\n",
      "        1,  1,  2,  1,  1,  1,  1,  1, 24,  1,  1,  2,  1,  1,  1,  2,  1,\n",
      "        1,  3,  1,  2,  2,  1,  1,  1,  1,  9,  1,  1,  1,  1,  3,  1,  1,\n",
      "        1,  1,  1,  1,  1,  1,  2,  1,  1,  8,  1,  1,  1,  1,  1,  1,  1,\n",
      "        1,  1,  1, 15,  1,  1,  1,  1,  3,  1,  1,  1,  1,  7,  1,  1,  1,\n",
      "        1,  1,  1,  6,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,\n",
      "        1,  5,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  1,  1,  7,  1,\n",
      "        1,  1,  1,  1,  1,  1,  2,  2,  1,  5,  1,  1,  1,  1,  1,  1,  1,\n",
      "        1,  1,  1,  1,  4,  1,  1,  1,  1,  6,  1,  1,  1,  1,  1,  1,  1,\n",
      "        1,  1,  3,  1,  1,  1,  1,  1,  1,  1,  3,  1,  1,  1,  1,  1,  1,\n",
      "        5,  1,  3,  1,  1,  2,  3,  1,  1,  1,  1,  1,  4,  1,  1,  1,  2,\n",
      "        6,  1,  1,  1,  1,  8,  1,  1,  1,  1,  1,  3,  1,  1,  1,  3,  1,\n",
      "        1,  1,  2,  1,  1,  1,  2,  1,  2,  1,  1,  2,  2,  1,  1,  1,  1,\n",
      "        3,  1,  1,  1,  1,  1,  2,  1,  1,  1,  3,  1,  1,  2,  1,  1,  1,\n",
      "        1,  1,  2,  1,  1,  1,  1,  1,  1,  1,  1,  3,  1,  1,  1,  1,  1,\n",
      "        2,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  1,  1,  1,  1,  1,\n",
      "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "        1], dtype=int64))\n",
      "(array([    7,     8,     9, ..., 27820, 28093, 33017], dtype=int64), array([64, 62, 52, ...,  1,  1,  1], dtype=int64))\n",
      "(array([    7,     8,     9, ..., 35499, 42821, 46133], dtype=int64), array([22, 25, 22, ...,  1,  1,  1], dtype=int64))\n",
      "(array([   1,    2,    3,    4,    5,    6,    7,    8,    9,   10,   11,\n",
      "         12,   13,   14,   15,   16,   17,   18,   19,   20,   21,   22,\n",
      "         23,   24,   25,   26,   27,   28,   29,   30,   31,   32,   33,\n",
      "         34,   35,   36,   37,   38,   39,   40,   41,   42,   43,   44,\n",
      "         45,   46,   47,   48,   49,   50,   51,   52,   53,   54,   55,\n",
      "         56,   57,   58,   59,   60,   61,   62,   63,   64,   65,   66,\n",
      "         67,   68,   69,   70,   71,   72,   73,   74,   75,   76,   77,\n",
      "         78,   79,   80,   81,   82,   83,   84,   85,   86,   87,   88,\n",
      "         89,   90,   91,   92,   93,   94,   95,   96,   97,   98,   99,\n",
      "        100,  101,  102,  103,  104,  105,  106,  107,  108,  109,  110,\n",
      "        111,  112,  113,  114,  115,  116,  117,  118,  119,  120,  121,\n",
      "        122,  123,  124,  125,  126,  127,  128,  129,  130,  131,  132,\n",
      "        133,  134,  135,  136,  137,  138,  139,  140,  141,  142,  143,\n",
      "        144,  145,  146,  147,  148,  149,  150,  151,  152,  153,  154,\n",
      "        155,  156,  157,  158,  159,  160,  161,  162,  163,  164,  165,\n",
      "        166,  167,  168,  169,  170,  171,  172,  173,  174,  175,  176,\n",
      "        177,  178,  179,  180,  181,  182,  183,  184,  185,  186,  187,\n",
      "        188,  189,  190,  191,  192,  193,  194,  195,  196,  197,  198,\n",
      "        199,  200,  201,  202,  203,  204,  205,  206,  207,  208,  209,\n",
      "        210,  211,  212,  213,  214,  215,  216,  217,  218,  219,  220,\n",
      "        221,  222,  223,  224,  225,  226,  227,  228,  229,  230,  231,\n",
      "        232,  233,  234,  235,  236,  237,  238,  239,  240,  241,  242,\n",
      "        243,  244,  245,  246,  247,  248,  249,  250,  251,  252,  253,\n",
      "        254,  255,  256,  257,  258,  259,  260,  261,  262,  263,  264,\n",
      "        265,  266,  267,  268,  269,  270,  272,  273,  274,  275,  276,\n",
      "        278,  279,  282,  283,  284,  285,  286,  287,  288,  289,  290,\n",
      "        291,  292,  293,  294,  295,  296,  297,  298,  299,  300,  302,\n",
      "        303,  304,  305,  306,  307,  308,  309,  310,  311,  312,  313,\n",
      "        314,  315,  316,  317,  318,  319,  320,  321,  322,  323,  324,\n",
      "        325,  326,  327,  328,  329,  330,  331,  332,  333,  334,  336,\n",
      "        338,  339,  340,  341,  342,  343,  344,  345,  348,  349,  351,\n",
      "        352,  353,  354,  355,  356,  357,  358,  359,  360,  361,  362,\n",
      "        364,  365,  366,  368,  369,  370,  371,  372,  373,  374,  375,\n",
      "        377,  378,  380,  381,  382,  383,  384,  385,  386,  387,  388,\n",
      "        389,  390,  391,  392,  393,  394,  395,  396,  397,  398,  399,\n",
      "        400,  401,  402,  403,  404,  405,  407,  408,  409,  410,  411,\n",
      "        412,  414,  415,  416,  417,  418,  419,  420,  421,  422,  423,\n",
      "        424,  425,  427,  428,  429,  431,  432,  433,  438,  439,  440,\n",
      "        441,  443,  444,  447,  448,  449,  450,  452,  454,  455,  456,\n",
      "        458,  459,  460,  461,  462,  463,  465,  466,  467,  469,  470,\n",
      "        471,  472,  473,  476,  477,  478,  479,  481,  482,  485,  486,\n",
      "        488,  492,  495,  499,  501,  503,  505,  506,  507,  511,  513,\n",
      "        514,  515,  518,  520,  521,  525,  526,  527,  530,  532,  533,\n",
      "        534,  537,  542,  543,  544,  546,  547,  548,  551,  554,  555,\n",
      "        556,  557,  559,  561,  563,  564,  566,  569,  572,  573,  575,\n",
      "        576,  578,  579,  585,  586,  590,  593,  596,  599,  603,  607,\n",
      "        608,  609,  612,  613,  614,  617,  618,  621,  623,  624,  632,\n",
      "        636,  637,  640,  643,  645,  646,  650,  651,  654,  657,  658,\n",
      "        661,  662,  664,  669,  671,  674,  675,  676,  678,  679,  689,\n",
      "        691,  697,  703,  707,  718,  731,  745,  751,  752,  773,  776,\n",
      "        784,  786,  789,  799,  835,  838,  839,  885,  888,  901, 1003,\n",
      "       1025, 1028, 1134, 1142, 1218, 1227, 1292, 1356, 1481, 1488, 1634,\n",
      "       1641, 1644, 1651, 1756, 1815, 2273, 2333, 2925, 3212], dtype=int64), array([256,  79,  75,  71,  55,  84,  62,  75,  74,  67,  77,  74,  68,\n",
      "        91,  71,  63,  61,  66,  66,  63,  70,  48,  51,  45,  44,  55,\n",
      "        59,  49,  45,  42,  51,  38,  35,  35,  41,  32,  24,  30,  42,\n",
      "        42,  36,  37,  36,  32,  31,  27,  22,  29,  26,  27,  19,  26,\n",
      "        26,  24,  34,  39,  33,  30,  36,  27,  38,  27,  22,  27,  27,\n",
      "        26,  18,  18,  29,  24,  17,  14,  14,  19,  18,  12,  26,  13,\n",
      "        22,  19,  19,  20,  20,  21,  14,  20,  21,  15,  15,   8,  21,\n",
      "         8,  14,   9,  12,  14,  10,  13,  10,  12,   7,  12,  10,   9,\n",
      "        12,  11,  10,  14,  10,  14,  13,  16,  10,  12,  13,  11,   8,\n",
      "         7,  14,  20,  13,  18,  14,  14,  13,   9,   9,   6,  11,   9,\n",
      "         9,   8,   4,   7,  11,   4,  13,  11,   8,   9,   4,   5,   6,\n",
      "        10,   5,  13,   5,   3,  11,   8,   9,   5,   4,   9,   9,   8,\n",
      "         4,   6,   8,   9,   7,   5,   5,  11,   8,   6,   9,   7,   3,\n",
      "         4,  10,   4,   5,   6,   6,   6,  11,  12,   6,   5,  10,   4,\n",
      "         6,   5,   2,   6,   8,   3,   5,   8,   6,   5,   6,   2,   8,\n",
      "         5,   5,   8,   6,   4,   4,   7,   6,   3,   4,   3,   7,   4,\n",
      "         2,   4,   4,   8,  11,   5,   5,   2,   5,   8,   2,   8,   7,\n",
      "         6,   5,   1,   3,   3,   7,   6,   4,   2,   1,   1,   1,   5,\n",
      "         5,   4,   6,   5,   5,   1,   2,   3,   4,   2,   3,   4,   2,\n",
      "         2,   1,   1,   2,   2,   3,   3,   2,   4,   3,   5,   1,   2,\n",
      "         2,   1,   2,   3,   1,   2,   5,   3,   2,   3,   2,   1,   7,\n",
      "         4,   6,   4,   5,   2,   1,   1,   2,   4,   1,   2,   2,   1,\n",
      "         1,   3,   3,   2,   1,   2,   1,   2,   2,   2,   3,   2,   2,\n",
      "         2,   5,   3,   2,   1,   5,   3,   2,   1,   2,   2,   4,   4,\n",
      "         3,   3,   2,   1,   1,   1,   1,   4,   5,   3,   1,   1,   3,\n",
      "         1,   1,   3,   3,   3,   2,   3,   4,   2,   2,   1,   5,   2,\n",
      "         5,   2,   5,   3,   4,   2,   4,   4,   1,   6,   1,   2,   2,\n",
      "         2,   4,   3,   1,   2,   3,   2,   4,   1,   2,   1,   5,   3,\n",
      "         3,   2,   3,   2,   2,   1,   4,   5,   1,   5,   3,   4,   3,\n",
      "         2,   2,   1,   2,   1,   5,   6,   5,   3,   5,   1,   2,   1,\n",
      "         2,   2,   3,   2,   3,   1,   2,   1,   1,   1,   1,   4,   2,\n",
      "         3,   2,   2,   3,   2,   2,   1,   2,   1,   4,   3,   1,   1,\n",
      "         1,   1,   3,   2,   4,   1,   3,   2,   2,   2,   2,   3,   2,\n",
      "         3,   1,   1,   2,   2,   2,   2,   1,   2,   1,   2,   1,   1,\n",
      "         1,   1,   3,   1,   1,   4,   3,   3,   2,   1,   1,   1,   1,\n",
      "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   2,   1,\n",
      "         2,   2,   3,   2,   1,   2,   2,   1,   1,   1,   1,   2,   2,\n",
      "         1,   1,   3,   1,   1,   1,   2,   1,   3,   1,   1,   1,   2,\n",
      "         3,   1,   1,   3,   3,   1,   1,   1,   3,   1,   1,   1,   1,\n",
      "         1,   2,   2,   1,   1,   1,   1,   1,   1,   2,   1,   1,   1,\n",
      "         1,   1,   1,   1,   1,   2,   2,   1,   1,   1,   2,   1,   2,\n",
      "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "         1,   1,   1,   1,   1,   1,   1,   1,   1], dtype=int64))\n",
      "(array([1, 2, 3, 4, 5], dtype=int64), array([4913,  329,   28,   88,  115], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(np.unique(df[col],return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "## mapping Label 1 to 0(inliers) Label(2,3,4,5) to 1 outlier\n",
    "df.label[df.label == 1] = 0\n",
    "df.label[df.label == 2] = 1\n",
    "df.label[df.label == 3] = 1\n",
    "df.label[df.label == 4] = 1\n",
    "df.label[df.label == 5] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>1.400</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.657</td>\n",
       "      <td>2.33</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>1.167</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.881</td>\n",
       "      <td>3.60</td>\n",
       "      <td>18</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>108</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.741</td>\n",
       "      <td>4.43</td>\n",
       "      <td>31</td>\n",
       "      <td>80</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>1.400</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.743</td>\n",
       "      <td>4.33</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.944</td>\n",
       "      <td>2.25</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   F1  F2   F3     F4     F5     F6    F7  F8  F9  F10  label\n",
       "0   5   7   35  1.400  0.400  0.657  2.33  14  23    6      0\n",
       "1   6   7   42  1.167  0.429  0.881  3.60  18  37    5      0\n",
       "2   6  18  108  3.000  0.287  0.741  4.43  31  80    7      0\n",
       "3   5   7   35  1.400  0.371  0.743  4.33  13  26    3      0\n",
       "4   6   3   18  0.500  0.500  0.944  2.25   9  17    4      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([4913,  560], dtype=int64))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df.label, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4913, 11)\n",
      "(560, 11)\n"
     ]
    }
   ],
   "source": [
    "df_norm = df[df.label == 0]\n",
    "df_anom = df[df.label == 1]\n",
    "ds_norm = df_norm.values\n",
    "ds_anom = df_anom.values\n",
    "print(ds_norm.shape)\n",
    "print(ds_anom.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4700, 10) (4700,)\n"
     ]
    }
   ],
   "source": [
    "X_train = ds_norm[:4700, :-1]\n",
    "Y_train = ds_norm[:4700, -1]\n",
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(773, 10)\n",
      "(773,)\n"
     ]
    }
   ],
   "source": [
    "l = ds_norm.shape[0] - X_train.shape[0] \n",
    "no_of_test_samples = l + ds_anom.shape[0]\n",
    "no_of_features = X_train.shape[1]\n",
    "\n",
    "X_test = np.zeros((no_of_test_samples, no_of_features))\n",
    "Y_test = np.zeros((no_of_test_samples,))\n",
    "\n",
    "X_test[:l, :] = ds_norm[4700:, :-1]\n",
    "X_test[l:, :] = ds_anom[:,:-1]\n",
    "print(X_test.shape)\n",
    "Y_test[:l,] = ds_norm[4700:, -1]\n",
    "Y_test[l:,] = ds_anom[:, -1]\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4700, 10) (4700,)\n",
      "(773, 10) (773,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK : Constants\n",
    "omega = 1.\n",
    "\n",
    "class ELM(object):\n",
    "    def __init__(self, sess, batch_size, input_len, hidden_num, output_len, W, b):\n",
    "        '''\n",
    "        Args:\n",
    "          sess : TensorFlow session.\n",
    "          batch_size : The batch size (N)\n",
    "          input_len : The length of input. (L)\n",
    "          hidden_num : The number of hidden node. (K)\n",
    "          output_len : The length of output. (O)\n",
    "          W : randomly initialized weights\n",
    "          b : randomly initialized bias\n",
    "        '''\n",
    "    \n",
    "        self._sess = sess \n",
    "        self._batch_size = batch_size\n",
    "        self._input_len = input_len\n",
    "        self._hidden_num = hidden_num\n",
    "        self._output_len = output_len \n",
    "\n",
    "        # for train\n",
    "        self._x0 = tf.placeholder(tf.float32, [self._batch_size, self._input_len])\n",
    "        self._t0 = tf.placeholder(tf.float32, [self._batch_size, self._output_len])\n",
    "\n",
    "        # for test\n",
    "        self._x1 = tf.placeholder(tf.float32, [None, self._input_len])\n",
    "        self._t1 = tf.placeholder(tf.float32, [None, self._output_len])\n",
    "\n",
    "#         self._W = tf.Variable(\n",
    "#           tf.random_normal([self._input_len, self._hidden_num]),\n",
    "#           trainable=False, dtype=tf.float32)\n",
    "#         self._b = tf.Variable(\n",
    "#           tf.random_normal([self._hidden_num]),\n",
    "#           trainable=False, dtype=tf.float32)\n",
    "\n",
    "        ## Wts initialisation\n",
    "        self._W = W\n",
    "        self._b = b\n",
    "        \n",
    "        self._beta = tf.Variable(\n",
    "          tf.zeros([self._hidden_num, self._output_len]),\n",
    "          trainable=False, dtype=tf.float32)\n",
    "        self._var_list = [self._W, self._b, self._beta]\n",
    "\n",
    "        self.H0 = tf.matmul(self._x0, self._W) + self._b # N x L\n",
    "        self.H0_T = tf.transpose(self.H0)\n",
    "\n",
    "        self.H1 = tf.matmul(self._x1, self._W) + self._b # N x L\n",
    "        self.H1_T = tf.transpose(self.H1)\n",
    "\n",
    "        # beta analytic solution : self._beta_s (K x O)\n",
    "        if self._input_len < self._hidden_num: # L < K\n",
    "            identity = tf.constant(np.identity(self._hidden_num), dtype=tf.float32)\n",
    "            self._beta_s = tf.matmul(tf.matmul(tf.matrix_inverse(\n",
    "                tf.matmul(self.H0_T, self.H0) + identity/omega), \n",
    "                self.H0_T), self._t0)\n",
    "          # _beta_s = (H_T*H + I/om)^(-1)*H_T*T\n",
    "        else:\n",
    "            identity = tf.constant(np.identity(self._batch_size), dtype=tf.float32)\n",
    "            self._beta_s = tf.matmul(tf.matmul(self.H0_T, tf.matrix_inverse(\n",
    "                tf.matmul(self.H0, self.H0_T)+identity/omega)), self._t0)\n",
    "          # _beta_s = H_T*(H*H_T + I/om)^(-1)*T\n",
    "\n",
    "        self._assign_beta = self._beta.assign(self._beta_s)\n",
    "        self._fx0 = tf.matmul(self.H0, self._beta)\n",
    "        self._fx1 = tf.matmul(self.H1, self._beta)\n",
    "\n",
    "        self._cost = tf.reduce_mean(tf.cast(tf.losses.mean_squared_error(labels=self._t0, predictions=self._fx0), tf.float32))\n",
    "                                        \n",
    "        self._init = False\n",
    "        self._feed = False\n",
    "\n",
    "        # Cost for every sample point\n",
    "#         self._correct_prediction = tf.equal(tf.argmax(self._fx1,1), tf.argmax(self._t1,1))\n",
    "#         self._accuracy = tf.reduce_mean(tf.cast(self._correct_prediction, tf.float32))\n",
    "        self._testcost = tf.cast(tf.losses.mean_squared_error(labels=self._t1, predictions=self._fx1), tf.float32)\n",
    "\n",
    "\n",
    "    def feed(self, x, t):\n",
    "        '''\n",
    "        Args :\n",
    "          x : input array (N x L)\n",
    "          t : label array (N x O)\n",
    "        '''\n",
    "\n",
    "        if not self._init : self.init()\n",
    "        self._sess.run(self._assign_beta, {self._x0:x, self._t0:t})\n",
    "#         print(self._sess.run(self._cost, {self._x0:x, self._t0:t}))\n",
    "        \n",
    "        self._feed = True\n",
    "\n",
    "    def init(self):\n",
    "        self._sess.run(tf.initialize_variables(self._var_list))\n",
    "        self._init = True\n",
    "\n",
    "    def test(self, x, t=None):\n",
    "        if not self._feed : exit(\"Not feed-forward trained\")\n",
    "        if t is not None :\n",
    "#             print(\"Accuracy: {:.9f}\".format(self._sess.run(self._accuracy, {self._x1:x, self._t1:t})))\n",
    "            return self._sess.run(self._testcost, {self._x1:x, self._t1:t})\n",
    "            \n",
    "        else :\n",
    "            return self._sess.run(self._fx1, {self._x1:x})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size : 4700\n",
      "hidden_num : 150\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "batch_size = X_train.shape[0]\n",
    "hidden_num = 150\n",
    "input_len = X_train.shape[1]\n",
    "print(\"batch_size : {}\".format(batch_size))\n",
    "print(\"hidden_num : {}\".format(hidden_num))\n",
    "print(input_len)\n",
    "W = tf.Variable(\n",
    "  tf.random_normal([input_len, hidden_num]),\n",
    "  trainable=False, dtype=tf.float32)\n",
    "b = tf.Variable(\n",
    "  tf.random_normal([hidden_num]),\n",
    "  trainable=False, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init list of W and b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "init_list = []\n",
    "for i in range(10):\n",
    "        init_list.append((tf.Variable(tf.random_normal([input_len, hidden_num],seed=i),trainable=False, dtype=tf.float32),tf.Variable(tf.random_normal([hidden_num], seed=i),trainable=False, dtype=tf.float32)))\n",
    "print(len(init_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(anom_pred):\n",
    "    cnt = 0\n",
    "    for pt in anom_pred:\n",
    "        if pt[1]>=ds_norm.shape[0]-X_train.shape[0] and pt[1]<X_test.shape[0]:\n",
    "            cnt+=1\n",
    "    return (cnt/float(ds_anom.shape[0]))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "WARNING:tensorflow:From c:\\users\\asus\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:118: initialize_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.variables_initializer` instead.\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = {}\n",
    "itr = 0\n",
    "best_W = tf.Variable(tf.zeros([input_len,hidden_num]))\n",
    "best_b = tf.Variable(tf.zeros([hidden_num]))\n",
    "best_acc = 0.0\n",
    "best_acc_idx = 0\n",
    "\n",
    "for W,b in init_list:\n",
    "    print(itr)\n",
    "    ## feed W,b from list and evaluate error and accuracy corresponding to them\n",
    "    elm = ELM(sess, batch_size, input_len, hidden_num, input_len, W, b)\n",
    "    train_x, train_y = (X_train[:batch_size], X_train[:batch_size])\n",
    "\n",
    "    elm.feed(train_x, train_y)\n",
    "    \n",
    "    ## error list\n",
    "    err = []\n",
    "    for idx,test_pt in enumerate(X_test):\n",
    "        x = test_pt.reshape(1,-1)\n",
    "        err.append((elm.test(x, x), idx))\n",
    "    \n",
    "    err.sort(reverse=True)\n",
    "    \n",
    "    anom_pred = err[:ds_anom.shape[0]]\n",
    "    \n",
    "    acc = accuracy(anom_pred) \n",
    "    \n",
    "    results[itr] = [(err,acc)]\n",
    "    itr += 1\n",
    "    if acc>best_acc:\n",
    "        best_W = W\n",
    "        best_b = b\n",
    "        best_acc = acc\n",
    "        best_acc_idx = itr-1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.17857142857143\n",
      "62.142857142857146\n",
      "68.21428571428572\n",
      "64.28571428571429\n",
      "64.64285714285715\n",
      "64.64285714285715\n",
      "66.96428571428571\n",
      "64.46428571428572\n",
      "67.14285714285714\n",
      "65.71428571428571\n"
     ]
    }
   ],
   "source": [
    "for k in results.keys():\n",
    "    print(results[k][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(295457260000.0, 270),\n",
       " (282408220000.0, 268),\n",
       " (268851690000.0, 288),\n",
       " (145523970000.0, 295),\n",
       " (53234217000.0, 372),\n",
       " (24691188000.0, 649),\n",
       " (20501270000.0, 659),\n",
       " (18825013000.0, 646),\n",
       " (17536270000.0, 677),\n",
       " (15169264000.0, 608),\n",
       " (8864511000.0, 671),\n",
       " (6837156400.0, 678),\n",
       " (6809726000.0, 730),\n",
       " (5365658600.0, 267),\n",
       " (4759533000.0, 314),\n",
       " (4517569500.0, 559),\n",
       " (4340976600.0, 636),\n",
       " (3291523800.0, 653),\n",
       " (3208444700.0, 658),\n",
       " (3018996700.0, 642),\n",
       " (2854772700.0, 597),\n",
       " (2326020400.0, 725),\n",
       " (2071779600.0, 602),\n",
       " (1513710000.0, 603),\n",
       " (1506124900.0, 374),\n",
       " (1293374700.0, 621),\n",
       " (1224221400.0, 294),\n",
       " (1190589400.0, 501),\n",
       " (1047243800.0, 660),\n",
       " (1004940900.0, 414),\n",
       " (982664000.0, 341),\n",
       " (904037060.0, 483),\n",
       " (860757300.0, 50),\n",
       " (819965000.0, 596),\n",
       " (786712450.0, 335),\n",
       " (777147500.0, 640),\n",
       " (405957470.0, 560),\n",
       " (401057340.0, 352),\n",
       " (356313660.0, 669),\n",
       " (303886100.0, 385),\n",
       " (301816160.0, 400),\n",
       " (293985630.0, 0),\n",
       " (283936260.0, 20),\n",
       " (263848830.0, 482),\n",
       " (239524770.0, 25),\n",
       " (235455180.0, 29),\n",
       " (232598020.0, 657),\n",
       " (221361070.0, 12),\n",
       " (201205340.0, 366),\n",
       " (190808820.0, 139),\n",
       " (185140480.0, 31),\n",
       " (184385500.0, 405),\n",
       " (184320930.0, 11),\n",
       " (166564300.0, 41),\n",
       " (166156660.0, 271),\n",
       " (163385520.0, 15),\n",
       " (156997330.0, 700),\n",
       " (156118180.0, 36),\n",
       " (153673060.0, 741),\n",
       " (149951580.0, 375),\n",
       " (139523920.0, 743),\n",
       " (133796110.0, 198),\n",
       " (124991360.0, 554),\n",
       " (121947224.0, 14),\n",
       " (119902980.0, 30),\n",
       " (118543790.0, 682),\n",
       " (113830210.0, 576),\n",
       " (113344810.0, 620),\n",
       " (107398580.0, 348),\n",
       " (102637500.0, 160),\n",
       " (98038616.0, 377),\n",
       " (97312600.0, 686),\n",
       " (96304400.0, 368),\n",
       " (94328184.0, 610),\n",
       " (89842750.0, 745),\n",
       " (88917940.0, 495),\n",
       " (86345010.0, 158),\n",
       " (85820440.0, 26),\n",
       " (85521170.0, 687),\n",
       " (81800300.0, 358),\n",
       " (81557590.0, 21),\n",
       " (81464910.0, 8),\n",
       " (78995890.0, 558),\n",
       " (77642810.0, 34),\n",
       " (74982920.0, 16),\n",
       " (74305944.0, 434),\n",
       " (74008344.0, 457),\n",
       " (72256880.0, 516),\n",
       " (71265110.0, 143),\n",
       " (70201190.0, 459),\n",
       " (67464080.0, 458),\n",
       " (64856950.0, 507),\n",
       " (62878824.0, 77),\n",
       " (60062056.0, 99),\n",
       " (59766110.0, 679),\n",
       " (58794560.0, 435),\n",
       " (57997972.0, 37),\n",
       " (56107756.0, 57),\n",
       " (53811668.0, 722),\n",
       " (52952256.0, 114),\n",
       " (52461416.0, 112),\n",
       " (49110264.0, 81),\n",
       " (48282430.0, 44),\n",
       " (47658956.0, 370),\n",
       " (45057476.0, 105),\n",
       " (45032536.0, 654),\n",
       " (43344710.0, 42),\n",
       " (42167096.0, 67),\n",
       " (41897196.0, 62),\n",
       " (40442860.0, 69),\n",
       " (39847716.0, 107),\n",
       " (39177590.0, 472),\n",
       " (38857068.0, 113),\n",
       " (38789184.0, 471),\n",
       " (38549584.0, 289),\n",
       " (38017664.0, 70),\n",
       " (37970116.0, 35),\n",
       " (37651010.0, 101),\n",
       " (36690440.0, 43),\n",
       " (35543096.0, 60),\n",
       " (35046504.0, 111),\n",
       " (33247610.0, 547),\n",
       " (31742812.0, 186),\n",
       " (30584330.0, 433),\n",
       " (30484378.0, 66),\n",
       " (30346716.0, 408),\n",
       " (30158938.0, 515),\n",
       " (30099494.0, 541),\n",
       " (29734934.0, 490),\n",
       " (29350950.0, 125),\n",
       " (29245396.0, 108),\n",
       " (29171430.0, 479),\n",
       " (27757238.0, 681),\n",
       " (25908186.0, 83),\n",
       " (25595124.0, 274),\n",
       " (24311508.0, 536),\n",
       " (23396396.0, 17),\n",
       " (23004300.0, 436),\n",
       " (21029386.0, 96),\n",
       " (20545574.0, 209),\n",
       " (19792418.0, 103),\n",
       " (19431228.0, 567),\n",
       " (18474620.0, 680),\n",
       " (17867956.0, 565),\n",
       " (16313024.0, 180),\n",
       " (16289894.0, 204),\n",
       " (16283198.0, 137),\n",
       " (15493691.0, 184),\n",
       " (15343021.0, 181),\n",
       " (15248598.0, 704),\n",
       " (14975443.0, 191),\n",
       " (14847366.0, 494),\n",
       " (14554165.0, 714),\n",
       " (14277352.0, 535),\n",
       " (14232493.0, 65),\n",
       " (13852837.0, 710),\n",
       " (13700458.0, 48),\n",
       " (13093472.0, 188),\n",
       " (13073515.0, 85),\n",
       " (13047294.0, 505),\n",
       " (12378874.0, 711),\n",
       " (11844510.0, 13),\n",
       " (11625374.0, 190),\n",
       " (11623673.0, 379),\n",
       " (11398610.0, 178),\n",
       " (11281878.0, 534),\n",
       " (11252126.0, 203),\n",
       " (11060953.0, 196),\n",
       " (11045287.0, 439),\n",
       " (10656385.0, 380),\n",
       " (10646850.0, 530),\n",
       " (10638293.0, 208),\n",
       " (10163703.0, 4),\n",
       " (10066963.0, 484),\n",
       " (9999802.0, 503),\n",
       " (9834826.0, 497),\n",
       " (9552525.0, 549),\n",
       " (8765605.0, 150),\n",
       " (8302590.5, 102),\n",
       " (8041505.5, 499),\n",
       " (8003408.0, 340),\n",
       " (7956019.0, 6),\n",
       " (7947658.5, 376),\n",
       " (7927266.5, 76),\n",
       " (7654085.5, 205),\n",
       " (7349311.0, 56),\n",
       " (7158831.0, 476),\n",
       " (7081599.0, 736),\n",
       " (6985953.0, 580),\n",
       " (6924533.0, 500),\n",
       " (6920397.0, 173),\n",
       " (6905549.5, 488),\n",
       " (6893101.0, 207),\n",
       " (6829757.5, 61),\n",
       " (6794031.0, 189),\n",
       " (6711749.5, 506),\n",
       " (6662684.5, 546),\n",
       " (6625743.0, 80),\n",
       " (6495944.0, 171),\n",
       " (6477543.0, 545),\n",
       " (6449900.0, 478),\n",
       " (6449145.0, 512),\n",
       " (6439572.5, 533),\n",
       " (6353709.0, 758),\n",
       " (6339883.0, 473),\n",
       " (6190926.5, 163),\n",
       " (6032845.0, 168),\n",
       " (6021325.0, 192),\n",
       " (5950135.0, 106),\n",
       " (5899232.0, 544),\n",
       " (5805413.5, 531),\n",
       " (5794955.0, 698),\n",
       " (5769698.0, 260),\n",
       " (5702579.0, 514),\n",
       " (5519111.0, 492),\n",
       " (5372145.5, 701),\n",
       " (5339828.0, 78),\n",
       " (5315595.0, 539),\n",
       " (5148032.5, 720),\n",
       " (5093353.5, 543),\n",
       " (5089029.5, 487),\n",
       " (5065973.0, 104),\n",
       " (4997936.5, 182),\n",
       " (4975485.0, 485),\n",
       " (4965489.5, 59),\n",
       " (4923267.0, 126),\n",
       " (4848358.0, 493),\n",
       " (4805724.0, 520),\n",
       " (4694630.0, 164),\n",
       " (4675815.5, 486),\n",
       " (4538122.0, 540),\n",
       " (4535696.5, 477),\n",
       " (4484765.0, 71),\n",
       " (4471354.0, 716),\n",
       " (4245065.5, 217),\n",
       " (4174058.5, 756),\n",
       " (4131296.0, 616),\n",
       " (4128337.2, 551),\n",
       " (3971214.5, 1),\n",
       " (3753234.0, 179),\n",
       " (3721133.2, 296),\n",
       " (3674754.0, 769),\n",
       " (3671186.8, 201),\n",
       " (3658993.5, 510),\n",
       " (3632426.0, 552),\n",
       " (3616091.2, 523),\n",
       " (3574598.8, 100),\n",
       " (3490816.5, 504),\n",
       " (3288315.2, 98),\n",
       " (2953781.8, 93),\n",
       " (2929853.2, 427),\n",
       " (2775939.5, 635),\n",
       " (2775281.5, 51),\n",
       " (2768500.2, 717),\n",
       " (2751751.2, 24),\n",
       " (2724980.8, 705),\n",
       " (2665860.8, 538),\n",
       " (2664752.0, 755),\n",
       " (2645030.5, 532),\n",
       " (2570428.2, 110),\n",
       " (2537551.8, 230),\n",
       " (2512082.5, 47),\n",
       " (2458205.2, 269),\n",
       " (2455841.0, 401),\n",
       " (2389004.8, 734),\n",
       " (2279981.8, 729),\n",
       " (2234610.5, 425),\n",
       " (2205676.5, 771),\n",
       " (2204097.8, 480),\n",
       " (2203481.2, 751),\n",
       " (2199668.0, 569),\n",
       " (2133686.5, 149),\n",
       " (2127224.0, 142),\n",
       " (2072912.8, 86),\n",
       " (2059004.8, 721),\n",
       " (2048399.0, 82),\n",
       " (2012324.0, 373),\n",
       " (2004602.6, 742),\n",
       " (1889935.6, 170),\n",
       " (1883677.2, 95),\n",
       " (1875608.8, 731),\n",
       " (1864475.6, 696),\n",
       " (1840504.4, 489),\n",
       " (1836103.6, 519),\n",
       " (1801986.8, 702),\n",
       " (1759447.6, 141),\n",
       " (1743856.8, 7),\n",
       " (1732466.2, 637),\n",
       " (1677846.2, 744),\n",
       " (1664762.1, 283),\n",
       " (1654880.9, 529),\n",
       " (1579239.2, 89),\n",
       " (1568389.1, 548),\n",
       " (1534449.9, 58),\n",
       " (1534324.9, 723),\n",
       " (1508812.2, 254),\n",
       " (1507681.5, 63),\n",
       " (1486659.2, 675),\n",
       " (1484607.2, 522),\n",
       " (1471415.6, 278),\n",
       " (1454468.4, 166),\n",
       " (1454056.2, 430),\n",
       " (1419822.1, 116),\n",
       " (1376887.4, 299),\n",
       " (1361870.6, 338),\n",
       " (1314553.0, 193),\n",
       " (1290774.9, 344),\n",
       " (1284392.6, 272),\n",
       " (1279269.2, 262),\n",
       " (1226486.0, 443),\n",
       " (1210621.8, 2),\n",
       " (1187951.2, 754),\n",
       " (1179939.8, 255),\n",
       " (1175337.2, 765),\n",
       " (1169151.9, 90),\n",
       " (1142920.9, 388),\n",
       " (1142823.0, 88),\n",
       " (1124890.6, 349),\n",
       " (1119756.8, 79),\n",
       " (1112513.2, 526),\n",
       " (1112056.8, 155),\n",
       " (1095656.4, 674),\n",
       " (1093702.8, 463),\n",
       " (1082922.1, 502),\n",
       " (1071390.2, 517),\n",
       " (1064173.0, 409),\n",
       " (1042349.6, 232),\n",
       " (1018906.6, 445),\n",
       " (1002558.5, 568),\n",
       " (998670.6, 53),\n",
       " (991769.7, 586),\n",
       " (987517.0, 542),\n",
       " (983941.0, 124),\n",
       " (966120.4, 440),\n",
       " (962617.6, 735),\n",
       " (953722.7, 738),\n",
       " (946224.5, 695),\n",
       " (941299.9, 175),\n",
       " (940937.8, 211),\n",
       " (868239.6, 197),\n",
       " (865400.4, 264),\n",
       " (860364.2, 371),\n",
       " (856125.4, 496),\n",
       " (837270.1, 387),\n",
       " (832479.1, 614),\n",
       " (804359.0, 52),\n",
       " (803009.56, 145),\n",
       " (796423.75, 265),\n",
       " (793269.5, 604),\n",
       " (778276.7, 121),\n",
       " (778187.94, 508),\n",
       " (776305.4, 553),\n",
       " (754022.4, 322),\n",
       " (749948.7, 229),\n",
       " (747000.1, 592),\n",
       " (740816.4, 117),\n",
       " (738877.8, 426),\n",
       " (711260.9, 491),\n",
       " (688553.6, 634),\n",
       " (683333.25, 415),\n",
       " (674646.9, 331),\n",
       " (674422.44, 222),\n",
       " (672553.75, 250),\n",
       " (665489.75, 709),\n",
       " (644177.8, 448),\n",
       " (641134.1, 418),\n",
       " (637981.8, 156),\n",
       " (626709.1, 389),\n",
       " (602771.7, 300),\n",
       " (591706.56, 513),\n",
       " (590204.1, 92),\n",
       " (582885.44, 311),\n",
       " (580178.6, 247),\n",
       " (578515.2, 202),\n",
       " (567482.1, 115),\n",
       " (563374.44, 673),\n",
       " (560926.56, 692),\n",
       " (558123.56, 537),\n",
       " (533159.9, 466),\n",
       " (531159.9, 134),\n",
       " (520142.94, 759),\n",
       " (510642.7, 287),\n",
       " (500375.8, 699),\n",
       " (491286.1, 309),\n",
       " (481686.6, 212),\n",
       " (479786.2, 739),\n",
       " (467663.84, 72),\n",
       " (462826.7, 68),\n",
       " (460757.5, 318),\n",
       " (458522.7, 672),\n",
       " (450915.7, 151),\n",
       " (447081.9, 213),\n",
       " (422115.25, 518),\n",
       " (417877.47, 528),\n",
       " (413754.84, 732),\n",
       " (411646.5, 521),\n",
       " (409925.12, 768),\n",
       " (405072.2, 345),\n",
       " (404925.66, 691),\n",
       " (401848.9, 73),\n",
       " (399606.66, 94),\n",
       " (398439.4, 712),\n",
       " (397610.34, 386),\n",
       " (395985.56, 266),\n",
       " (394347.6, 346),\n",
       " (392903.66, 3),\n",
       " (388691.56, 54),\n",
       " (374867.25, 214),\n",
       " (369409.2, 87),\n",
       " (365767.94, 594),\n",
       " (364807.78, 390),\n",
       " (359527.8, 5),\n",
       " (345743.7, 33),\n",
       " (343616.8, 152),\n",
       " (341592.88, 64),\n",
       " (334717.38, 157),\n",
       " (331144.8, 708),\n",
       " (316544.97, 726),\n",
       " (315270.2, 249),\n",
       " (308323.7, 239),\n",
       " (305174.78, 234),\n",
       " (297204.1, 763),\n",
       " (297089.5, 650),\n",
       " (295717.84, 23),\n",
       " (295189.78, 422),\n",
       " (293294.25, 279),\n",
       " (291022.44, 275),\n",
       " (290647.03, 129),\n",
       " (284464.6, 605),\n",
       " (281904.12, 282),\n",
       " (280027.5, 276),\n",
       " (278970.66, 19),\n",
       " (276649.72, 383),\n",
       " (272368.0, 343),\n",
       " (265095.44, 122),\n",
       " (262404.0, 148),\n",
       " (261940.33, 450),\n",
       " (256243.83, 509),\n",
       " (253898.5, 320),\n",
       " (244032.66, 123),\n",
       " (241695.42, 663),\n",
       " (238306.75, 690),\n",
       " (236453.25, 465),\n",
       " (236038.25, 226),\n",
       " (235841.34, 273),\n",
       " (231747.84, 575),\n",
       " (231747.84, 561),\n",
       " (229908.25, 146),\n",
       " (229584.34, 469),\n",
       " (228262.9, 651),\n",
       " (223187.0, 574),\n",
       " (219498.9, 511),\n",
       " (218709.62, 18),\n",
       " (212811.9, 120),\n",
       " (203420.56, 706),\n",
       " (202806.42, 321),\n",
       " (202420.72, 28),\n",
       " (198708.6, 195),\n",
       " (198354.5, 216),\n",
       " (196369.17, 45),\n",
       " (196262.05, 316),\n",
       " (196161.53, 38),\n",
       " (195776.95, 46),\n",
       " (193909.39, 413),\n",
       " (190813.6, 609),\n",
       " (184954.45, 252),\n",
       " (179228.81, 307),\n",
       " (178151.75, 241),\n",
       " (177590.58, 10),\n",
       " (177338.19, 556),\n",
       " (176914.86, 645),\n",
       " (175224.03, 652),\n",
       " (173695.52, 728),\n",
       " (172026.6, 281),\n",
       " (171474.25, 612),\n",
       " (170897.97, 22),\n",
       " (170171.84, 442),\n",
       " (169445.48, 55),\n",
       " (161294.45, 323),\n",
       " (156640.53, 285),\n",
       " (156574.97, 394),\n",
       " (154481.2, 27),\n",
       " (149214.28, 437),\n",
       " (148314.4, 527),\n",
       " (147859.14, 131),\n",
       " (147511.67, 334),\n",
       " (146846.84, 261),\n",
       " (144515.1, 326),\n",
       " (144327.4, 365),\n",
       " (141764.17, 410),\n",
       " (141059.62, 291),\n",
       " (140882.55, 766),\n",
       " (139693.17, 578),\n",
       " (136532.23, 670),\n",
       " (135261.5, 424),\n",
       " (134487.33, 248),\n",
       " (133634.75, 625),\n",
       " (130788.266, 498),\n",
       " (127363.234, 308),\n",
       " (124387.266, 613),\n",
       " (124248.75, 474),\n",
       " (121844.33, 460),\n",
       " (120306.71, 562),\n",
       " (120165.67, 286),\n",
       " (117826.48, 277),\n",
       " (116080.0, 32),\n",
       " (114275.484, 598),\n",
       " (114161.08, 563),\n",
       " (110665.15, 328),\n",
       " (109218.67, 431),\n",
       " (109054.92, 336),\n",
       " (108656.79, 243),\n",
       " (108184.086, 676),\n",
       " (108184.086, 577),\n",
       " (107552.29, 132),\n",
       " (107539.875, 172),\n",
       " (107501.27, 109),\n",
       " (106730.08, 301),\n",
       " (105514.02, 130),\n",
       " (105248.086, 420),\n",
       " (105180.83, 416),\n",
       " (104938.75, 438),\n",
       " (104682.66, 428),\n",
       " (104353.664, 39),\n",
       " (103453.11, 256),\n",
       " (100712.016, 395),\n",
       " (100152.46, 724),\n",
       " (98346.45, 455),\n",
       " (97430.23, 199),\n",
       " (95767.55, 263),\n",
       " (95304.33, 644),\n",
       " (95115.02, 633),\n",
       " (92318.67, 412),\n",
       " (91446.41, 332),\n",
       " (91210.46, 579),\n",
       " (90749.89, 325),\n",
       " (89565.91, 611),\n",
       " (87617.234, 432),\n",
       " (87393.45, 319),\n",
       " (86894.336, 9),\n",
       " (86712.71, 303),\n",
       " (86680.016, 302),\n",
       " (85254.19, 550),\n",
       " (83823.36, 339),\n",
       " (81858.83, 417),\n",
       " (80703.2, 683),\n",
       " (80499.08, 357),\n",
       " (77338.734, 251),\n",
       " (76647.664, 231),\n",
       " (75857.14, 655),\n",
       " (75690.63, 631),\n",
       " (75690.63, 581),\n",
       " (75329.1, 419),\n",
       " (74414.89, 402),\n",
       " (73852.71, 524),\n",
       " (71358.37, 615),\n",
       " (68911.0, 97),\n",
       " (68405.55, 564),\n",
       " (67648.59, 404),\n",
       " (67624.52, 292),\n",
       " (67353.12, 133),\n",
       " (62604.543, 305),\n",
       " (62365.85, 593),\n",
       " (61760.25, 347),\n",
       " (59774.25, 661),\n",
       " (59625.094, 391),\n",
       " (58975.4, 237),\n",
       " (58212.79, 75),\n",
       " (57252.914, 630),\n",
       " (57153.438, 238),\n",
       " (54571.258, 447),\n",
       " (54375.26, 555),\n",
       " (53043.7, 353),\n",
       " (52712.65, 177),\n",
       " (52699.4, 183),\n",
       " (52422.023, 684),\n",
       " (51309.273, 140),\n",
       " (51247.23, 464),\n",
       " (50979.65, 128),\n",
       " (50509.43, 407),\n",
       " (49574.016, 176),\n",
       " (49000.203, 623),\n",
       " (47037.566, 244),\n",
       " (46699.1, 165),\n",
       " (45270.85, 421),\n",
       " (45063.66, 470),\n",
       " (45047.867, 127),\n",
       " (41662.023, 74),\n",
       " (41447.46, 290),\n",
       " (41389.52, 362),\n",
       " (40669.117, 174),\n",
       " (40280.797, 187),\n",
       " (40164.69, 750),\n",
       " (39294.453, 118),\n",
       " (38957.67, 693),\n",
       " (37827.133, 582),\n",
       " (37105.26, 161),\n",
       " (37016.934, 297),\n",
       " (36945.883, 136),\n",
       " (36655.3, 40),\n",
       " (35853.88, 162),\n",
       " (34719.535, 585),\n",
       " (33905.125, 599),\n",
       " (33894.9, 733),\n",
       " (33739.05, 317),\n",
       " (33692.117, 452),\n",
       " (33197.973, 350),\n",
       " (32840.04, 624),\n",
       " (32773.656, 767),\n",
       " (32714.363, 570),\n",
       " (32432.691, 665),\n",
       " (32341.588, 719),\n",
       " (32341.588, 715),\n",
       " (32341.588, 467),\n",
       " (32213.291, 219),\n",
       " (32030.785, 147),\n",
       " (31991.396, 747),\n",
       " (31952.078, 453),\n",
       " (31883.682, 293),\n",
       " (31187.27, 622),\n",
       " (31015.562, 306),\n",
       " (29961.941, 200),\n",
       " (29700.13, 215),\n",
       " (29586.99, 703),\n",
       " (29256.074, 468),\n",
       " (28772.744, 770),\n",
       " (28772.744, 557),\n",
       " (28619.95, 748),\n",
       " (28241.338, 685),\n",
       " (27611.605, 399),\n",
       " (27046.672, 227),\n",
       " (26972.832, 566),\n",
       " (26861.223, 446),\n",
       " (25991.098, 329),\n",
       " (25960.785, 206),\n",
       " (25785.832, 228),\n",
       " (25586.02, 456),\n",
       " (25545.49, 185),\n",
       " (25514.076, 258),\n",
       " (25426.719, 392),\n",
       " (25191.402, 628),\n",
       " (24644.879, 218),\n",
       " (24463.215, 423),\n",
       " (24444.346, 406),\n",
       " (23741.32, 342),\n",
       " (23208.14, 324),\n",
       " (23160.37, 233),\n",
       " (22994.354, 333),\n",
       " (22994.354, 327),\n",
       " (22671.256, 194),\n",
       " (22433.312, 355),\n",
       " (22261.178, 760),\n",
       " (22261.178, 626),\n",
       " (22261.178, 591),\n",
       " (22115.863, 584),\n",
       " (21977.48, 647),\n",
       " (21925.688, 337),\n",
       " (21815.893, 330),\n",
       " (21400.379, 91),\n",
       " (21338.113, 313),\n",
       " (21219.87, 235),\n",
       " (20963.27, 662),\n",
       " (20695.191, 220),\n",
       " (20060.22, 589),\n",
       " (19838.303, 656),\n",
       " (19654.611, 475),\n",
       " (19494.14, 749),\n",
       " (19318.441, 525),\n",
       " (19318.441, 224),\n",
       " (18634.11, 590),\n",
       " (18581.266, 588),\n",
       " (18538.777, 315),\n",
       " (18440.188, 304),\n",
       " (18348.621, 666),\n",
       " (18055.787, 583),\n",
       " (17653.234, 382),\n",
       " (17402.79, 364),\n",
       " (16922.512, 144),\n",
       " (16670.725, 253),\n",
       " (16245.766, 246),\n",
       " (16107.232, 595),\n",
       " (15185.817, 119),\n",
       " (15126.763, 601),\n",
       " (15126.763, 360),\n",
       " (14921.419, 449),\n",
       " (14848.225, 312),\n",
       " (14673.15, 707),\n",
       " (14671.799, 587),\n",
       " (14578.6875, 403),\n",
       " (14402.719, 444),\n",
       " (14059.083, 571),\n",
       " (14059.083, 284),\n",
       " (13538.381, 221),\n",
       " (13235.447, 153),\n",
       " (13015.394, 648),\n",
       " (13015.394, 363),\n",
       " (13015.394, 359),\n",
       " (13015.394, 354),\n",
       " (12581.295, 384),\n",
       " (12366.803, 481),\n",
       " (12314.853, 240),\n",
       " (12134.552, 159),\n",
       " (12102.357, 169),\n",
       " (11782.914, 310),\n",
       " (11742.463, 740),\n",
       " (11742.463, 617),\n",
       " (11742.463, 223),\n",
       " (11153.943, 84),\n",
       " (11062.701, 639),\n",
       " (11062.701, 638),\n",
       " (10713.516, 259),\n",
       " (10166.821, 618),\n",
       " (9644.95, 369),\n",
       " (9634.543, 764),\n",
       " (9273.044, 607),\n",
       " (9273.044, 356),\n",
       " (9194.69, 573),\n",
       " (9138.865, 135),\n",
       " (8957.0, 49),\n",
       " (8856.188, 138),\n",
       " (8722.701, 242),\n",
       " (8591.67, 396),\n",
       " (8492.3955, 441),\n",
       " (8280.326, 454),\n",
       " (8228.05, 280),\n",
       " (8098.332, 688),\n",
       " (7735.322, 737),\n",
       " (7735.322, 718),\n",
       " (7735.322, 713),\n",
       " (7735.322, 236),\n",
       " (7735.322, 225),\n",
       " (7643.2373, 752),\n",
       " (7643.2373, 627),\n",
       " (7643.2373, 381),\n",
       " (7366.6743, 694),\n",
       " (6460.6514, 167),\n",
       " (6174.454, 762),\n",
       " (6174.454, 727),\n",
       " (6174.454, 668),\n",
       " (6174.454, 643),\n",
       " (6174.454, 641),\n",
       " (6174.454, 619),\n",
       " (6174.454, 462),\n",
       " (6174.454, 351),\n",
       " (6044.8037, 572),\n",
       " (6044.8037, 298),\n",
       " (5840.2554, 451),\n",
       " (5302.8374, 397),\n",
       " (5302.8374, 393),\n",
       " (5251.8345, 429),\n",
       " (5251.8345, 411),\n",
       " (4867.0605, 772),\n",
       " (4867.0605, 753),\n",
       " (4867.0605, 689),\n",
       " (4867.0605, 632),\n",
       " (4867.0605, 629),\n",
       " (4867.0605, 461),\n",
       " (4807.779, 210),\n",
       " (4361.3037, 398),\n",
       " (4147.788, 154),\n",
       " (3720.6375, 761),\n",
       " (3720.6375, 757),\n",
       " (3720.6375, 746),\n",
       " (3720.6375, 606),\n",
       " (3720.6375, 600),\n",
       " (3720.6375, 367),\n",
       " (3707.0923, 697),\n",
       " (3339.4285, 245),\n",
       " (2991.267, 664),\n",
       " (2048.1401, 257),\n",
       " (1866.1648, 378),\n",
       " (1866.1648, 361),\n",
       " (1763.9844, 667)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err = results[best_acc_idx][0][0]\n",
    "err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_array = np.array(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD8CAYAAACINTRsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAENFJREFUeJzt3X+sZGV9x/HPpyyg/Kgs7oVs+eEFQzaS1C7kZgulMVWKIm1AE03YNHSbYLZppQFr0iw2afQ/ahSbJg12LVTSINUKFAK0ullpiI1ZexcXdrcLBXSLC+vupUQh/acC3/4xz4VxuT9mzo+Z5zzn/Upu5syZM/d85zzP8zlnzvxyRAgAUIZfmnYBAIDmEOoAUBBCHQAKQqgDQEEIdQAoCKEOAAUh1AGgIIQ6ABSEUAeAgqyZ5MrWrVsXs7Ozk1wlAHTe7t27X4yImVGWnWioz87Oan5+fpKrBIDOs/3foy7L6RcAKAihDgAFIdQBoCCEOgAUhFAHgIIQ6gBQEEIdAApCqANAQQh1ACgIoQ4ABSHUAaAghDoAFIRQB4CCEOoAUBBCHVMxu+2haZcAFIlQB4CCrBrqts+x/YjtA7b3274xzf+s7edt70l/V7VfLgBgJaP88tGrkj4dEY/ZPlXSbts70m1fiogvtFceAGAcq4Z6RByWdDhNv2L7gKSz2i4MADC+sc6p256VdJGkXWnWDbafsH2H7bUN1wYAGNPIoW77FEn3SLopIl6WdJukd0vaqMGR/BeXud9W2/O25xcWFhooGQCwnJFC3fbxGgT6XRFxryRFxJGIeC0iXpf0FUmblrpvRGyPiLmImJuZmWmqbgDAEkZ594sl3S7pQETcOjR//dBiH5W0r/nyAADjGOXdL5dJuk7SXtt70rzPSNpse6OkkHRQ0h+2UiEAYGSjvPvlu5K8xE0PN18OAKAOPlEKAAUh1AGgIIQ6ABSEUAeAghDqAFAQQh0ACkKoA0BBCHUAKAihDgAFIdQBoCCEOgAUhFAH0Hmz2x6adgnZINQBoCCEOoCi9P2onVAHgIIQ6mhM34+QgBwQ6gDegh10dxHqAFAQQh0ACkKoA+iExVNCnBpaGaEOoFGE7nQR6gBQEEIdAApCqANoBadhpoNQB4CCEOroHY4gUTJCHQAKQqgDHcUzDiyFUEenTSPYCFPkjFAHMsYOBONaNdRtn2P7EdsHbO+3fWOaf7rtHbafTpdr2y8XQB+wM6tulCP1VyV9OiLeI+kSSZ+0faGkbZJ2RsQFknam6wCAKVo11CPicEQ8lqZfkXRA0lmSrpF0Z1rsTkkfaatIAMBoxjqnbntW0kWSdkk6MyIOS4Pgl3RG08UBAMYzcqjbPkXSPZJuioiXx7jfVtvztucXFhaq1AgAGNFIoW77eA0C/a6IuDfNPmJ7fbp9vaSjS903IrZHxFxEzM3MzDRRMwBgGaO8+8WSbpd0ICJuHbrpAUlb0vQWSfc3Xx4AYBxrRljmMknXSdpre0+a9xlJt0j6hu3rJT0n6ePtlAgAGNWqoR4R35XkZW6+vNlyAAB18IlSACgIoQ4ABSHU0Qt87Bx9UWyoHzuIGdQA+qDYUF9EmAPok+JDHQD6hFAH8IZJPbPlGXR7CHUUg6AACHUAEzCtHW4fd/SdDPWlGmpxXmmNWNrjAdCuTob6sFJCr5THgemjL/Vb50O9bQwQAF1CqLeEnUF/0faYpl6FOoMNQOl6FeqjIvwBdBWh3jB2CACmiVAvCDsUAIT6BBG6yEnJ/bHkx7YaQh3omT4HXh8Q6gBQEEK9ZzhKw7joM91CqANAQQj1AvDTfcD4Sh03hHphSumYAKrpdKgTYGyDOvq47fr4mEdR0nbpdKhjZSV1VCyNNsaxCPUMMVAxafS5chDqDWFQdAvthVL1PtS7+jN4XasX9dDeGFXvQ70rurrzwXiqtHPdPkGfKguhDvTEcHj3/SCh5Me9aqjbvsP2Udv7huZ91vbztvekv6vaLbNdJTcwykJfxWpGOVL/qqQrl5j/pYjYmP4ebrYsAEAVq4Z6RDwq6aUJ1IKWcHQH9Eedc+o32H4inZ5Zu9xCtrfanrc9v7CwUGN1AIDVVA312yS9W9JGSYclfXG5BSNie0TMRcTczMxMxdU1j6NXNIn+1Ay2Y32VQj0ijkTEaxHxuqSvSNrUbFndRscEMC2VQt32+qGrH5W0b7llAVST08FBTrVMWtfe/jnKWxrvlvQ9SRtsH7J9vaTP295r+wlJ75f0qZbrnLquNCiA9uWcB6O8+2VzRKyPiOMj4uyIuD0irouIX42I90bE1RFxeBLFAkAdTYZxrsHOJ0oryLUxJ4ltAOSJUEdnsWMB3opQR22l/tYjUMe0xgGhPoJpNQ7hmJeq7THtdpz2+jFZhHoPMcgng+2MaSDUM0IItK/UbVzq48L4CPWWdW2wda1e5IO+kwdCHVOVUxDkVAsmp7R2J9QrGqUjlNZZSns8JepzG/X5sQ8j1DExDDrkoPTfdCXUka3cB0/u2H7N6dK27FSoN71hq/y/pX68t4u6XPtSSj/6Qj19at9OhXrb+tTwAMpUVKgTys1Z7jukR93GpTyjWU3Jj60JbJ/JKyrUc1YlDFHWu4y6Uie6rYhQZ7Cgy5rqv5MYBzmNtZxqyUkRoX6slRp7Gh0h186Xa13ApJQ4BooMdbSrxIHQFrbVm+q+2wyjIdQxEXUG56QHdhPrI4wwLYQ60EGl7DRKeRw5IdTRmnEHbN8GeN8eLyaDUJ8CBnM1bLc85NwOOdc2KYQ6MAbOtw+08Rhy2y651TMqQh2oYLkB39UgQDkI9ZoYxGXL7TMPXcc2ax+hjizkPNhzrq1tfX7sXUWoAxNAOK6Md0o1h1DPQNUOOslvQuzSIOrDi3jAcgj1FRAOzev7418J2wZNINQBVMJOKE+rhrrtO2wftb1vaN7ptnfYfjpdrm23TLSFgTlZbO/8jdNGqy07jfYe5Uj9q5KuPGbeNkk7I+ICSTvTdQAVEfblmnTbrhrqEfGopJeOmX2NpDvT9J2SPtJwXWgBwTEethe6qOo59TMj4rAkpcszllvQ9lbb87bnFxYWKq4OeBNhi5xNu3+2/kJpRGyPiLmImJuZmWl7daho2h1xWE61TEPfHz/qqRrqR2yvl6R0ebS5kgCCDaOhn7xV1VB/QNKWNL1F0v3NlAMAqGOUtzTeLel7kjbYPmT7ekm3SLrC9tOSrkjX0aBJHoFwtIM66D95WbPaAhGxeZmbLm+4FmAqAUEo5W1220M6eMvvTLuMzuATpWNg8APtY5zV08tQz6XT5FJHiZbatmzv6WC7T1YvQx3jqTMoGdDAZBHq6DV2Ov3R5u/L5tSPCHUUJafBhXpGbcs227yJ3zqYNEIdwEjYYXYDoQ4ALZvkDpFQB4CCEOoAGtfXUzU5PG5CHQAKQqgDQEEIdQAoCKEOAAUh1FFZDi8KAfhFhDqKxo4HfUOoA0BBCHUAKAihDgAFIdQBoCCEOgAUhFAHgIIQ6gBQEEIdAApCqANAQQh1ACgIoQ4ABSHUAaAghDoAFIRQB4CCEOoAUJA1de5s+6CkVyS9JunViJhroigAQDW1Qj15f0S82MD/AQDUxOkXAChI3VAPSd+2vdv21iYKAgBUV/f0y2UR8YLtMyTtsP1kRDw6vEAK+62SdO6559ZcHQBgJbWO1CPihXR5VNJ9kjYtscz2iJiLiLmZmZk6qwMArKJyqNs+2fapi9OSPihpX1OFAQDGV+f0y5mS7rO9+H++FhH/2khVAIBKKod6RPxQ0q81WAsAoCbe0ggABSHUAaAghDoAFIRQB4CCEOoAUBBCHQAKQqgDQEEIdQAoCKEOAAUh1AGgIIQ6ABSEUAeAghDqAFAQQh0ACkKoA0BBCHUAKAihDgAFIdQBoCCEOgAUhFAHgIIQ6gBQEEIdAApCqANAQQh1ACgIoQ4ABSHUAaAghDoAFIRQB4CCEOoAUBBCHQAKUivUbV9p+ynbz9je1lRRAIBqKoe67eMk/Y2kD0u6UNJm2xc2VRgAYHx1jtQ3SXomIn4YEf8n6R8lXdNMWQCAKuqE+lmSfjx0/VCaBwCYEkdEtTvaH5f0oYj4RLp+naRNEfEnxyy3VdLWdHWDpKcq1rpO0osV7zsJOddHbdXlXF/OtUl519e12t4VETOj3HlNjRUfknTO0PWzJb1w7EIRsV3S9hrrkSTZno+Iubr/py0510dt1eVcX861SXnXV3JtdU6//IekC2yfZ/sESddKeqDG/wMA1FT5SD0iXrV9g6RvSTpO0h0Rsb+xygAAY6tz+kUR8bCkhxuqZTW1T+G0LOf6qK26nOvLuTYp7/qKra3yC6UAgPzwNQEAUJBOhPq0v47A9h22j9reNzTvdNs7bD+dLtem+bb916nWJ2xf3HJt59h+xPYB2/tt35hZfW+z/X3bj6f6Ppfmn2d7V6rv6+nFdtk+MV1/Jt0+22Z9aZ3H2f6B7QczrO2g7b2299ieT/NyadvTbH/T9pOp/12aQ222N6Tttfj3su2bcqhtqMZPpfGwz/bdaZw00+8iIus/DV6EfVbS+ZJOkPS4pAsnXMP7JF0sad/QvM9L2pamt0n6yzR9laR/kWRJl0ja1XJt6yVdnKZPlfRfGnxtQy71WdIpafp4SbvSer8h6do0/8uS/ihN/7GkL6fpayV9fQLt+6eSvibpwXQ9p9oOSlp3zLxc2vZOSZ9I0ydIOi2X2oZqPE7STyS9K5faNPiQ5o8kvX2ov/1BU/2u9Y3awAa4VNK3hq7fLOnmKdQxq18M9ackrU/T6yU9lab/VtLmpZabUJ33S7oix/oknSTpMUm/rsGHK9Yc28YavJvq0jS9Ji3nFms6W9JOSR+Q9GAa2FnUltZzUG8N9am3raRfTsHk3Go7pp4PSvr3nGrTm5/GPz31owclfaipfteF0y+5fh3BmRFxWJLS5Rlp/tTqTU/LLtLgaDib+tLpjT2SjkraocEzr59GxKtL1PBGfen2n0l6Z4vl/ZWkP5P0err+zoxqk6SQ9G3buz34dLaUR9ueL2lB0t+nU1d/Z/vkTGobdq2ku9N0FrVFxPOSviDpOUmHNehHu9VQv+tCqHuJeTm/ZWcq9do+RdI9km6KiJdXWnSJea3WFxGvRcRGDY6KN0l6zwo1TKw+278r6WhE7B6evcL6p9G2l0XExRp8G+onbb9vhWUnWd8aDU5J3hYRF0n6Xw1OaSxn4tsunZO+WtI/rbboEvNaqy2dy79G0nmSfkXSyRq073I1jFVfF0J9pK8jmIIjttdLUro8muZPvF7bx2sQ6HdFxL251bcoIn4q6d80OG95mu3Fz0kM1/BGfen2d0h6qaWSLpN0te2DGnzL6Ac0OHLPoTZJUkS8kC6PSrpPg51iDm17SNKhiNiVrn9Tg5DPobZFH5b0WEQcSddzqe23Jf0oIhYi4ueS7pX0G2qo33Uh1HP9OoIHJG1J01s0OJe9OP/30yvql0j62eJTvjbYtqTbJR2IiFszrG/G9mlp+u0adOgDkh6R9LFl6lus+2OSvhPpZGLTIuLmiDg7ImY16FffiYjfy6E2SbJ9su1TF6c1OD+8Txm0bUT8RNKPbW9Isy6X9J851DZks9489bJYQw61PSfpEtsnpfG7uO2a6Xdtv1DR0AsLV2nwro5nJf35FNZ/twbnvn6uwV7zeg3Oae2U9HS6PD0taw1+PORZSXslzbVc229q8FTsCUl70t9VGdX3Xkk/SPXtk/QXaf75kr4v6RkNnh6fmOa/LV1/Jt1+/oTa+Lf05rtfsqgt1fF4+tu/2PczatuNkuZT2/6zpLUZ1XaSpP+R9I6heVnUltb5OUlPpjHxD5JObKrf8YlSAChIF06/AABGRKgDQEEIdQAoCKEOAAUh1AGgIIQ6ABSEUAeAghDqAFCQ/we36aHUaDfoMQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(err_array[:,1], np.log(err_array[:,0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 150)\n",
      "(150,)\n",
      "68.21428571428572\n"
     ]
    }
   ],
   "source": [
    "W_final = best_W.eval(session=sess)\n",
    "b_final = best_b.eval(session=sess)\n",
    "print(W_final.shape)\n",
    "print(b_final.shape)\n",
    "print(best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## One class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocSVM = OneClassSVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma='auto', kernel='rbf',\n",
       "      max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "      verbose=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocSVM.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = ocSVM.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[pred==1] = 0\n",
    "pred[pred==-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.sum(pred == Y_test)/X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6972833117723156"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data preparation for clustering algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5473, 10)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = X_train.shape[0]+X_test.shape[0]\n",
    "X = np.zeros((samples,X_train.shape[1]))\n",
    "X[:X_train.shape[0], :] = X_train[:, :]\n",
    "X[X_train.shape[0]:, :] = X_test[:, :]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5473,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.zeros(samples,)\n",
    "Y[:Y_train.shape[0]] = Y_train\n",
    "Y[Y_train.shape[0]:] = Y_test\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=50.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = dbscan.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6539375114196967"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = np.sum(pred==Y)/Y.shape[0]\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "lof = LocalOutlierFactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\scipy\\stats\\stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    }
   ],
   "source": [
    "pred = lof.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  1]), array([ 548, 4925], dtype=int64))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(pred, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[pred==1] = 0\n",
    "pred[pred == -1] = 1\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8750228393933858"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = np.sum(pred==Y)/Y.shape[0]\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy in percentage\n",
    "    ELM: 68.21\n",
    "    One Class SVM: 69.72\n",
    "    DBSCAN: 65.39\n",
    "    LOF: 87.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
